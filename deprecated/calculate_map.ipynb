{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv(\"/home/pangy/disk/LUO/test_only/TriDet/ground_truth_cataracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr =  pd.read_csv(\"/home/pangy/disk/LUO/test_only/TriDet/prediction_cataracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[\"t-start\"] = pr[\"t-start\"]*30\n",
    "pr[\"t-end\"] = pr[\"t-end\"]*30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.to_csv(\"/home/pangy/disk/LUO/test_only/TriDet/prediction_cataracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fad8a963d00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.groupby(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def remove_duplicate_annotations(ants, tol=1e-3):\n",
    "    # remove duplicate annotations (same category and starting/ending time)\n",
    "    valid_events = []\n",
    "    for event in ants:\n",
    "        s, e, l = event['segment'][0], event['segment'][1], event['label_id']\n",
    "        valid = True\n",
    "        for p_event in valid_events:\n",
    "            if ((abs(s - p_event['segment'][0]) <= tol)\n",
    "                    and (abs(e - p_event['segment'][1]) <= tol)\n",
    "                    and (l == p_event['label_id'])\n",
    "            ):\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            valid_events.append(event)\n",
    "    return valid_events\n",
    "\n",
    "\n",
    "def load_gt_seg_from_json(json_file, split=None, label='label', label_offset=0):\n",
    "    # load json file\n",
    "    with open(json_file, \"r\", encoding=\"utf8\") as f:\n",
    "        json_db = json.load(f)\n",
    "\n",
    "    vids, starts, stops, labels = [], [], [], []\n",
    "    if split == \"training\":\n",
    "        split_name = \"train\"\n",
    "    else:\n",
    "        split_name = \"test\"\n",
    "    for k, v in json_db.items():\n",
    "\n",
    "        for segments in v[\"annotation\"]:\n",
    "            if split_name not in segments[\"subset\"]:\n",
    "                continue\n",
    "            ants = segments\n",
    "            vids.append(k.split(\".\")[0])\n",
    "            starts.append(ants[\"start\"])\n",
    "            stops.append(ants[\"end\"])\n",
    "            labels.append(ants[\"label\"])\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"# filter based on split\n",
    "        if split_name not in k:\n",
    "            continue\n",
    "        # remove duplicated instances\n",
    "        ants = v\n",
    "        # video id\n",
    "        vids += [k] * len(ants)\n",
    "        # for each event, grab the start/end time and label\n",
    "        for event in ants:\n",
    "            starts += [float(event['start'])]\n",
    "            stops += [float(event['end'])]\n",
    "            if isinstance(event[label], (Tuple, List)):\n",
    "                # offset the labels by label_offset\n",
    "                label_id = 0\n",
    "                for i, x in enumerate(event[label][::-1]):\n",
    "                    label_id += label_offset ** i + int(x)\n",
    "            else:\n",
    "                # load label_id directly\n",
    "                label_id = int(event[label])\n",
    "            labels += [label_id]\"\"\"\n",
    "\n",
    "    # move to pd dataframe\n",
    "    gt_base = pd.DataFrame({\n",
    "        'video-id': vids,\n",
    "        't-start': starts,\n",
    "        't-end': stops,\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "    return gt_base\n",
    "\n",
    "\n",
    "def load_pred_seg_from_json(json_file, label='label_id', label_offset=0):\n",
    "    # load json file\n",
    "    with open(json_file, \"r\", encoding=\"utf8\") as f:\n",
    "        json_db = json.load(f)\n",
    "    json_db = json_db['database']\n",
    "\n",
    "    vids, starts, stops, labels, scores = [], [], [], [], []\n",
    "    for k, v, in json_db.items():\n",
    "        # video id\n",
    "        vids += [k] * len(v[\"annotation\"])\n",
    "        # for each event\n",
    "        for event in v[\"annotation\"]:\n",
    "            starts += [float(event['segment'][0])]\n",
    "            stops += [float(event['segment'][1])]\n",
    "            if isinstance(event[label], (Tuple, List)):\n",
    "                # offset the labels by label_offset\n",
    "                label_id = 0\n",
    "                for i, x in enumerate(event[label][::-1]):\n",
    "                    label_id += label_offset ** i + int(x)\n",
    "            else:\n",
    "                # load label_id directly\n",
    "                label_id = int(event[label])\n",
    "            labels += [label_id]\n",
    "            scores += [float(event['scores'])]\n",
    "\n",
    "    # move to pd dataframe\n",
    "    pred_base = pd.DataFrame({\n",
    "        'video-id': vids,\n",
    "        't-start': starts,\n",
    "        't-end': stops,\n",
    "        'label': labels,\n",
    "        'score': scores\n",
    "    })\n",
    "\n",
    "    return pred_base\n",
    "\n",
    "\n",
    "class ANETdetection(object):\n",
    "    \"\"\"Adapted from https://github.com/activitynet/ActivityNet/blob/master/Evaluation/eval_detection.py\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ant_file,\n",
    "            split=None,\n",
    "            tiou_thresholds=np.linspace(0.1, 0.5, 5),\n",
    "            label='label',\n",
    "            label_offset=0,\n",
    "            num_workers=8,\n",
    "            dataset_name=None,\n",
    "    ):\n",
    "\n",
    "        self.tiou_thresholds = tiou_thresholds\n",
    "        self.ap = None\n",
    "        self.num_workers = num_workers\n",
    "        if dataset_name is not None:\n",
    "            self.dataset_name = dataset_name\n",
    "        else:\n",
    "            self.dataset_name = os.path.basename(ant_file).replace('.json', '')\n",
    "\n",
    "        # Import ground truth and predictions\n",
    "        self.split = split\n",
    "        self.ground_truth = load_gt_seg_from_json(\n",
    "            ant_file, split=self.split, label=label, label_offset=label_offset)\n",
    "\n",
    "        # remove labels that does not exists in gt\n",
    "        self.activity_index = {j: i for i, j in enumerate(sorted(self.ground_truth['label'].unique()))}\n",
    "        self.ground_truth['label'] = self.ground_truth['label'].replace(self.activity_index)\n",
    "        \n",
    "        # remove action instances with length=0\n",
    "        self.ground_truth = self.ground_truth.drop(\n",
    "            np.where(self.ground_truth['t-start'] == self.ground_truth['t-end'])[0])\n",
    "\n",
    "    def _get_predictions_with_label(self, prediction_by_label, label_name, cidx):\n",
    "        \"\"\"Get all predicitons of the given label. Return empty DataFrame if there\n",
    "        is no predcitions with the given label.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            res = prediction_by_label.get_group(cidx).reset_index(drop=True)\n",
    "            return res\n",
    "        except:\n",
    "            print('Warning: No predictions of label \\'%s\\' were provdied.' % label_name)\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def wrapper_compute_average_precision(self, preds):\n",
    "        \"\"\"Computes average precision for each class in the subset.\n",
    "        \"\"\"\n",
    "        ap = np.zeros((len(self.tiou_thresholds), len(self.activity_index)))\n",
    "\n",
    "        # Adaptation to query faster\n",
    "        ground_truth_by_label = self.ground_truth.groupby('label')\n",
    "        prediction_by_label = preds.groupby('label')\n",
    "\n",
    "        results = Parallel(n_jobs=self.num_workers)(\n",
    "            delayed(compute_average_precision_detection)(\n",
    "                ground_truth=ground_truth_by_label.get_group(cidx).reset_index(drop=True),\n",
    "                prediction=self._get_predictions_with_label(prediction_by_label, label_name, cidx),\n",
    "                tiou_thresholds=self.tiou_thresholds,\n",
    "            ) for label_name, cidx in self.activity_index.items())\n",
    "\n",
    "        for i, cidx in enumerate(self.activity_index.values()):\n",
    "            ap[:, cidx] = results[i]\n",
    "\n",
    "        return ap\n",
    "\n",
    "    def evaluate(self, preds, verbose=True):\n",
    "        \"\"\"Evaluates a prediction file. For the detection task we measure the\n",
    "        interpolated mean average precision to measure the performance of a\n",
    "        method.\n",
    "        preds can be (1) a pd.DataFrame; or (2) a json file where the data will be loaded;\n",
    "        or (3) a python dict item with numpy arrays as the values\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(preds, pd.DataFrame):\n",
    "            assert 'label' in preds\n",
    "        elif isinstance(preds, str) and os.path.isfile(preds):\n",
    "            preds = load_pred_seg_from_json(preds)\n",
    "        elif isinstance(preds, Dict):\n",
    "            # move to pd dataframe\n",
    "            # did not check dtype here, can accept both numpy / pytorch tensors\n",
    "            preds = pd.DataFrame({\n",
    "                'video-id': preds['video-id'],\n",
    "                't-start': preds['t-start'].tolist(),\n",
    "                't-end': preds['t-end'].tolist(),\n",
    "                'label': preds['label'].tolist(),\n",
    "                'score': preds['score'].tolist()\n",
    "            })\n",
    "        # always reset ap\n",
    "        self.ap = None\n",
    "\n",
    "        # make the label ids consistent\n",
    "        preds['label'] = preds['label'].replace(self.activity_index)\n",
    "\n",
    "        #reverse the labels and store csv file\n",
    "        reverse_activity_index = {v: k for k, v in self.activity_index.items()}\n",
    "        preds_original = preds.copy()\n",
    "        preds_original['label'].replace(reverse_activity_index)\n",
    "        ground_truth_original = self.ground_truth.copy()\n",
    "        ground_truth_original['label'].replace(reverse_activity_index)\n",
    "        ground_truth_original.to_csv(\"ground_truth_cataracts.csv\")\n",
    "        preds_original.to_csv(\"prediction_cataracts.csv\")\n",
    "        # compute mAP\n",
    "        self.ap = self.wrapper_compute_average_precision(preds)\n",
    "        mAP = self.ap.mean(axis=1)\n",
    "        average_mAP = mAP.mean()\n",
    "\n",
    "        # print results\n",
    "        if verbose:\n",
    "            # print the results\n",
    "            print('[RESULTS] Action detection results on {:s}.'.format(\n",
    "                self.dataset_name)\n",
    "            )\n",
    "            block = ''\n",
    "            for tiou, tiou_mAP in zip(self.tiou_thresholds, mAP):\n",
    "                block += '\\n|tIoU = {:.2f}: mAP = {:.2f} (%)'.format(tiou, tiou_mAP * 100)\n",
    "            print(block)\n",
    "            print('Avearge mAP: {:.2f} (%)'.format(average_mAP * 100))\n",
    "\n",
    "        # return the results\n",
    "        return mAP, average_mAP\n",
    "\n",
    "\n",
    "def compute_average_precision_detection(\n",
    "        ground_truth,\n",
    "        prediction,\n",
    "        tiou_thresholds=np.linspace(0.1, 0.5, 5)\n",
    "):\n",
    "    \"\"\"Compute average precision (detection task) between ground truth and\n",
    "    predictions data frames. If multiple predictions occurs for the same\n",
    "    predicted segment, only the one with highest score is matches as\n",
    "    true positive. This code is greatly inspired by Pascal VOC devkit.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : df\n",
    "        Data frame containing the ground truth instances.\n",
    "        Required fields: ['video-id', 't-start', 't-end']\n",
    "    prediction : df\n",
    "        Data frame containing the prediction instances.\n",
    "        Required fields: ['video-id, 't-start', 't-end', 'score']\n",
    "    tiou_thresholds : 1darray, optional\n",
    "        Temporal intersection over union threshold.\n",
    "    Outputs\n",
    "    -------\n",
    "    ap : float\n",
    "        Average precision score.\n",
    "    \"\"\"\n",
    "\n",
    "    ap = np.zeros(len(tiou_thresholds))\n",
    "    if prediction.empty:\n",
    "        return ap\n",
    "\n",
    "    npos = float(len(ground_truth))\n",
    "    lock_gt = np.ones((len(tiou_thresholds), len(ground_truth))) * -1\n",
    "    # Sort predictions by decreasing score order.\n",
    "    sort_idx = prediction['score'].values.argsort()[::-1]\n",
    "    prediction = prediction.loc[sort_idx].reset_index(drop=True)\n",
    "\n",
    "    # Initialize true positive and false positive vectors.\n",
    "    tp = np.zeros((len(tiou_thresholds), len(prediction)))\n",
    "    fp = np.zeros((len(tiou_thresholds), len(prediction)))\n",
    "\n",
    "    # Adaptation to query faster\n",
    "    ground_truth_gbvn = ground_truth.groupby('video-id')\n",
    "\n",
    "    # Assigning true positive to truly ground truth instances.\n",
    "    for idx, this_pred in prediction.iterrows():\n",
    "\n",
    "        try:\n",
    "            # Check if there is at least one ground truth in the video associated.\n",
    "            ground_truth_videoid = ground_truth_gbvn.get_group(this_pred['video-id'])\n",
    "        except Exception as e:\n",
    "            fp[:, idx] = 1\n",
    "            continue\n",
    "\n",
    "        this_gt = ground_truth_videoid.reset_index()\n",
    "        tiou_arr = segment_iou(this_pred[['t-start', 't-end']].values,\n",
    "                               this_gt[['t-start', 't-end']].values)\n",
    "        # We would like to retrieve the predictions with highest tiou score.\n",
    "        tiou_sorted_idx = tiou_arr.argsort()[::-1]\n",
    "        for tidx, tiou_thr in enumerate(tiou_thresholds):\n",
    "            for jdx in tiou_sorted_idx:\n",
    "                if tiou_arr[jdx] < tiou_thr:\n",
    "                    fp[tidx, idx] = 1\n",
    "                    break\n",
    "                if lock_gt[tidx, this_gt.loc[jdx]['index']] >= 0:\n",
    "                    continue\n",
    "                # Assign as true positive after the filters above.\n",
    "                tp[tidx, idx] = 1\n",
    "                lock_gt[tidx, this_gt.loc[jdx]['index']] = idx\n",
    "                break\n",
    "\n",
    "            if fp[tidx, idx] == 0 and tp[tidx, idx] == 0:\n",
    "                fp[tidx, idx] = 1\n",
    "\n",
    "    tp_cumsum = np.cumsum(tp, axis=1).astype(float)\n",
    "    fp_cumsum = np.cumsum(fp, axis=1).astype(float)\n",
    "    recall_cumsum = tp_cumsum / npos\n",
    "\n",
    "    precision_cumsum = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
    "\n",
    "    for tidx in range(len(tiou_thresholds)):\n",
    "        ap[tidx] = interpolated_prec_rec(precision_cumsum[tidx, :], recall_cumsum[tidx, :])\n",
    "\n",
    "    return ap\n",
    "\n",
    "\n",
    "def segment_iou(target_segment, candidate_segments):\n",
    "    \"\"\"Compute the temporal intersection over union between a\n",
    "    target segment and all the test segments.\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_segment : 1d array\n",
    "        Temporal target segment containing [starting, ending] times.\n",
    "    candidate_segments : 2d array\n",
    "        Temporal candidate segments containing N x [starting, ending] times.\n",
    "    Outputs\n",
    "    -------\n",
    "    tiou : 1d array\n",
    "        Temporal intersection over union score of the N's candidate segments.\n",
    "    \"\"\"\n",
    "    tt1 = np.maximum(target_segment[0], candidate_segments[:, 0])\n",
    "    tt2 = np.minimum(target_segment[1], candidate_segments[:, 1])\n",
    "    # Intersection including Non-negative overlap score.\n",
    "    segments_intersection = (tt2 - tt1).clip(0)\n",
    "    # Segment union.\n",
    "    segments_union = (candidate_segments[:, 1] - candidate_segments[:, 0]) \\\n",
    "                     + (target_segment[1] - target_segment[0]) - segments_intersection\n",
    "    # Compute overlap as the ratio of the intersection\n",
    "    # over union of two segments.\n",
    "    tIoU = segments_intersection.astype(float) / segments_union\n",
    "\n",
    "    if np.any(segments_union == 0) or np.any(np.isnan(segments_union)):\n",
    "        print(1)\n",
    "    return tIoU\n",
    "\n",
    "\n",
    "def interpolated_prec_rec(prec, rec):\n",
    "    \"\"\"Interpolated AP - VOCdevkit from VOC 2011.\n",
    "    \"\"\"\n",
    "    mprec = np.hstack([[0], prec, [0]])\n",
    "    mrec = np.hstack([[0], rec, [1]])\n",
    "    for i in range(len(mprec) - 1)[::-1]:\n",
    "        mprec[i] = max(mprec[i], mprec[i + 1])\n",
    "    idx = np.where(mrec[1::] != mrec[0:-1])[0] + 1\n",
    "    ap = np.sum((mrec[idx] - mrec[idx - 1]) * mprec[idx])\n",
    "    return ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tridet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
