{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part-1 Video/image feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxj/anaconda3/envs/surgplan/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/lxj/anaconda3/envs/surgplan/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Modified to process a list of videos\n",
    "\"\"\"Extract features for videos using pre-trained networks\"\"\"\n",
    "from feature_extract.configs.custom_config import load_config\n",
    "from slowfast.utils.misc import launch_job\n",
    "from slowfast.utils.parser import parse_args\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import av\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "import slowfast.utils.checkpoint as cu\n",
    "import slowfast.utils.distributed as du\n",
    "import slowfast.utils.logging as logging\n",
    "import slowfast.utils.misc as misc\n",
    "\n",
    "from feature_extract.models import build_model\n",
    "from feature_extract.datasets.extract_dataset import VideoSet\n",
    "import copy\n",
    "logger = logging.get_logger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from slowfast.datasets.utils import pack_pathway_output\n",
    "from feature_extract.configs.custom_config import load_config\n",
    "from slowfast.utils.parser import parse_args\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction configs\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse the following arguments for a default parser for PySlowFast users.\n",
    "    Args:\n",
    "        shard_id (int): shard id for the current machine. Starts from 0 to\n",
    "            num_shards - 1. If single machine is used, then set shard id to 0.\n",
    "        num_shards (int): number of shards using by the job.\n",
    "        init_method (str): initialization method to launch the job with multiple\n",
    "            devices. Options includes TCP or shared file-system for\n",
    "            initialization. details can be find in\n",
    "            https://pytorch.org/docs/stable/distributed.html#tcp-initialization\n",
    "        cfg (str): path to the config file.\n",
    "        opts (argument): provide addtional options from the command line, it\n",
    "            overwrites the config loaded from file.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Provide SlowFast video training and testing pipeline.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shard_id\",\n",
    "        help=\"The shard id of current node, Starts from 0 to num_shards - 1\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_shards\",\n",
    "        help=\"Number of shards using by the job\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--init_method\",\n",
    "        help=\"Initialization method, includes TCP or shared file-system\",\n",
    "        default=\"tcp://localhost:9999\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cfg\",\n",
    "        dest=\"cfg_files\",\n",
    "        help=\"Path to the config files\",\n",
    "        default=[\"/home/lxj/project/surgplan/LUO/slowfast/feature_extract/configs/SLOWFAST_8x8_R50_1031.yaml\"],\n",
    "        nargs=\"+\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"See slowfast/config/defaults.py for all options\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--f\",\n",
    "        help=\"for jupyternotebook to run\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个steram output feature的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction image process\n",
    "\n",
    "def pre_process_frame(arr):\n",
    "        \"\"\"\n",
    "        Pre process an array\n",
    "        Args:\n",
    "            arr (ndarray): an array of frames of shape T x H x W x C \n",
    "        Returns:\n",
    "            arr (tensor): a normalized torch tensor of shape C x T x H x W \n",
    "        \"\"\"\n",
    "        arr = torch.from_numpy(arr).float()\n",
    "        # Normalize the values\n",
    "        arr = arr / 255.0\n",
    "        #DATA.MEAN = [0.45, 0.45, 0.45]\n",
    "        arr = arr - torch.tensor([0.45, 0.45, 0.45])\n",
    "        #_C.DATA.STD = [0.225, 0.225, 0.225]\n",
    "        arr = arr / torch.tensor([0.225, 0.225, 0.225])\n",
    "\n",
    "        # T H W C -> C T H W.\n",
    "        try:\n",
    "            arr = arr.permute(3, 0, 1, 2)\n",
    "        except Exception as e:\n",
    "            print(\"length of the array is not T x H x W x C \")\n",
    "\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(input)的框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_taken(start_time, end_time):\n",
    "    hours = int((end_time - start_time) / 3600)\n",
    "    minutes = int((end_time - start_time) / 60) - (hours * 60)\n",
    "    seconds = int((end_time - start_time) % 60)\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "#feature extraction slow fast inference\n",
    "@torch.no_grad()\n",
    "def perform_inference(inputs, model, cfg):\n",
    "    \"\"\"\n",
    "    Perform mutli-view testing that samples a segment of frames from a video\n",
    "    and extract features from a pre-trained model.\n",
    "    Args:\n",
    "        test_loader (loader): video testing loader.\n",
    "        model (model): the pretrained video model to test.\n",
    "        cfg (CfgNode): configs. Details can be found in\n",
    "            slowfast/config/defaults.py\n",
    "    \"\"\"\n",
    "    # Enable eval mode.\n",
    "    model.eval()\n",
    "\n",
    "    feat_arr = None\n",
    "\n",
    "    # Transfer the data to the current GPU device.\n",
    "    if isinstance(inputs, (list,)):\n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i] = inputs[i].cuda(device=cfg.USED_GPU,non_blocking=True)\n",
    "    else:\n",
    "        inputs = inputs.cuda(device=cfg.USED_GPU,non_blocking=True)\n",
    "\n",
    "    # Perform the forward pass.\n",
    "    preds, feat = model(inputs)\n",
    "    # Gather all the predictions across all the devices to perform ensemble.\n",
    "    if cfg.NUM_GPUS > 1:\n",
    "        preds, feat = du.all_gather([preds, feat])\n",
    "\n",
    "    feat = feat.cpu().numpy()\n",
    "\n",
    "    if feat_arr is None:\n",
    "        feat_arr = feat\n",
    "    else:\n",
    "        feat_arr = np.concatenate((feat_arr, feat), axis=0)\n",
    "\n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video feature extraction stream output\n",
    "def test(model,cfg,inputs):\n",
    "    \"\"\"\n",
    "    Perform multi-view testing/feature extraction on the pretrained video model.\n",
    "    Args:\n",
    "        cfg (CfgNode): configs. Details can be found in\n",
    "            slowfast/config/defaults.py\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seed from configs.\n",
    "    np.random.seed(cfg.RNG_SEED)\n",
    "    torch.manual_seed(cfg.RNG_SEED)\n",
    "\n",
    "    # Setup logging format.\n",
    "    #logging.setup_logging(cfg.OUTPUT_DIR)\n",
    "\n",
    "    # Print config.\n",
    "    #logger.info(\"Test with config:\")\n",
    "    #logger.info(cfg)\n",
    "\n",
    "    # Build the video model and print model statistics.\n",
    "    \n",
    "    #if du.is_master_proc() and cfg.LOG_MODEL_INFO:\n",
    "        #misc.log_model_info(model, cfg, use_train_input=False)\n",
    "\n",
    "    #changes here\n",
    "    #checkpoint = torch.load(\"/data/disk/LUO/slowfast/feature_extract/checkpoints/checkpoint_epoch_00130.pyth\")\n",
    "    #model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    #cu.load_test_checkpoint(cfg, model)\n",
    "    # Perform multi-view test on the entire dataset.\n",
    "    feat_arr = perform_inference(inputs, model, cfg)\n",
    "    \n",
    "\n",
    "    return feat_arr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "\n",
    "# our code\n",
    "from libs.core import load_tridet_config\n",
    "from libs.datasets import make_dataset, make_data_loader\n",
    "from libs.modeling import make_meta_arch\n",
    "from libs.utils import valid_one_epoch, ANETdetection, fix_random_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from libs.datasets.datasets import register_dataset\n",
    "from libs.datasets.data_utils import truncate_feats\n",
    "from libs.utils import remove_duplicate_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_json(label_dict=None,split=['testing'],num_classes=19,json_file=\"/home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/data/cataract/data_1102.json\",default_fps=30):\n",
    "\n",
    "        #create a csv\n",
    "        #frame_start,frame_end,label,training_or_testing\n",
    "        # load database and select the subset\n",
    "        with open(json_file) as f:\n",
    "            json_data = json.load(f)\n",
    "        # if label_dict is not available, matching label(str) to label id (int)\n",
    "        if label_dict is None:\n",
    "            label_dict = {\n",
    "            #define surgical phase name to phase label id\n",
    "                \"phase_{}\".format(i+1):i for i in range(num_classes)\n",
    "            }\n",
    "            \n",
    "        if split[0] == \"training\":\n",
    "            split_name = \"train\"\n",
    "        else:\n",
    "            split_name = \"test\"\n",
    "        # fill in the db (immutable afterwards)\n",
    "        dict_db = tuple()\n",
    "        for key, value in json_data.items():\n",
    "            # key is the video id, v is the segement information\n",
    "            # get fps if available\n",
    "\n",
    "            if split_name not in value[\"annotation\"][0][\"subset\"]:\n",
    "                continue\n",
    "            if default_fps is not None:\n",
    "                fps = default_fps\n",
    "            else:\n",
    "                #fps=30\n",
    "                fps = 1\n",
    "\n",
    "            duration = []\n",
    "            num_phase = len(value[\"annotation\"])\n",
    "            segments = np.zeros([num_phase, 2], dtype=np.float32)\n",
    "            labels = np.zeros([num_phase, ], dtype=np.int64)\n",
    "            for idx,phase in enumerate(value[\"annotation\"]):\n",
    "                duration.append(phase[\"time_till_now\"])\n",
    "                segments[idx][0] = phase[\"start\"]\n",
    "                segments[idx][1] = phase[\"end\"]\n",
    "                if num_classes == 1:\n",
    "                    labels[idx] = 0\n",
    "                else:\n",
    "                    labels[idx] = phase[\"label\"]\n",
    "            last_time = value[\"last_time\"]\n",
    "            dict_db += ({'id': key.split(\".\")[0],\n",
    "                         'fps': fps,\n",
    "                         'duration': last_time,\n",
    "                         'segments': segments,\n",
    "                         'labels': labels\n",
    "                         },)\n",
    "\n",
    "        return dict_db, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(data_list,features, idx,num_frames,max_seq_len=1024,feat_stride=1,downsample_rate=1,force_upsampling=False,mirror=True):\n",
    "    # directly return a (truncated) data point (so it is very fast!)\n",
    "    # auto batching will be disabled in the subsequent dataloader\n",
    "    # instead the model will need to decide how to batch / preporcess the data\n",
    "    video_item = data_list[idx]\n",
    "\n",
    "    # load features\n",
    "    feats = features\n",
    "\n",
    "    #shape is T x 2304\n",
    "    # we support both fixed length features / variable length features\n",
    "    if feat_stride > 0 and (not force_upsampling):\n",
    "        # var length features\n",
    "        feat_stride, num_frames = feat_stride, num_frames\n",
    "        # only apply down sampling here\n",
    "        if downsample_rate > 1:\n",
    "            feats = feats[::downsample_rate, :]\n",
    "            feat_stride = feat_stride * downsample_rate\n",
    "\n",
    "    # T x C -> C x T\n",
    "    if isinstance(feats, torch.Tensor):\n",
    "        feats = feats.transpose(0, 1)\n",
    "    else:\n",
    "        feats = torch.from_numpy(np.ascontiguousarray(feats.transpose()))\n",
    "\n",
    "    # convert time stamp (in second) into temporal feature grids\n",
    "    # ok to have small negative values here\n",
    "    if video_item['segments'] is not None:\n",
    "        segments = torch.from_numpy(\n",
    "            #(video_item['segments'] * video_item['fps'] - 0.5 * num_frames) / (feat_stride)\n",
    "            video_item['segments']\n",
    "        )\n",
    "        labels = torch.from_numpy(video_item['labels'])\n",
    "        # for activity net, we have a few videos with a bunch of missing frames\n",
    "        # here is a quick fix for training\n",
    "        segments, labels = None, None\n",
    "\n",
    "    # return a data dict\n",
    "    data_dict = {'video_id': video_item['id'],\n",
    "                    'feats': feats,  # C x T\n",
    "                    'segments': segments,  # N x 2\n",
    "                    'labels': labels,  # N\n",
    "                    'fps': 30,\n",
    "                    'duration': num_frames,\n",
    "                    'feat_stride': 30,\n",
    "                    'feat_num_frames': 32}\n",
    "\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\n",
    "    Used to compute dataset stats from mini-batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = 0.0\n",
    "\n",
    "    def initialize(self, val, n):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * n\n",
    "        self.count = n\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, n)\n",
    "        else:\n",
    "            self.add(val, n)\n",
    "\n",
    "    def add(self, val, n):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(\n",
    "        dict_db,\n",
    "        model,\n",
    "        curr_epoch=0,\n",
    "        ext_score_file=None,\n",
    "        evaluator=None,\n",
    "        output_file=None,\n",
    "        tb_writer=None,\n",
    "        print_freq=20\n",
    "):\n",
    "    \"\"\"Test the model on the validation set\"\"\"\n",
    "    # either evaluate the results or save the results\n",
    "\n",
    "    # set up meters\n",
    "    batch_time = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    # dict for results (for our evaluation code)\n",
    "    results = {\n",
    "        'video-id': [],\n",
    "        't-start': [],\n",
    "        't-end': [],\n",
    "        'label': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    # loop over validation set\n",
    "    start = time.time()\n",
    "        # forward the model (wo. grad)\n",
    "    with torch.no_grad():\n",
    "        output = model(dict_db)\n",
    "\n",
    "        # upack the results into ANet format\n",
    "        num_vids = len(output)\n",
    "        for vid_idx in range(num_vids):\n",
    "            if output[vid_idx]['segments'].shape[0] > 0:\n",
    "                results['video-id'].extend(\n",
    "                    [output[vid_idx]['video_id']] *\n",
    "                    output[vid_idx]['segments'].shape[0]\n",
    "                )\n",
    "                results['t-start'].append(output[vid_idx]['segments'][:, 0])\n",
    "                results['t-end'].append(output[vid_idx]['segments'][:, 1])\n",
    "                results['label'].append(output[vid_idx]['labels'])\n",
    "                results['score'].append(output[vid_idx]['scores'])\n",
    "\n",
    "\n",
    "    # gather all stats and evaluate\n",
    "    results['t-start'] = torch.cat(results['t-start']).numpy()\n",
    "    results['t-end'] = torch.cat(results['t-end']).numpy()\n",
    "    results['label'] = torch.cat(results['label']).numpy()\n",
    "    results['score'] = torch.cat(results['score']).numpy()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "from typing import Dict\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt_seg_from_json(json_file, split=None, label='label', label_offset=0):\n",
    "    # load json file\n",
    "    with open(json_file, \"r\", encoding=\"utf8\") as f:\n",
    "        json_db = json.load(f)\n",
    "\n",
    "    vids, starts, stops, labels = [], [], [], []\n",
    "    if split == \"training\":\n",
    "        split_name = \"train\"\n",
    "    else:\n",
    "        split_name = \"test\"\n",
    "    for k, v in json_db.items():\n",
    "\n",
    "        for segments in v[\"annotation\"]:\n",
    "            if split_name not in segments[\"subset\"]:\n",
    "                continue\n",
    "            ants = segments\n",
    "            vids.append(k.split(\".\")[0])\n",
    "            starts.append(ants[\"start\"])\n",
    "            stops.append(ants[\"end\"])\n",
    "            labels.append(ants[\"label\"])\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"# filter based on split\n",
    "        if split_name not in k:\n",
    "            continue\n",
    "        # remove duplicated instances\n",
    "        ants = v\n",
    "        # video id\n",
    "        vids += [k] * len(ants)\n",
    "        # for each event, grab the start/end time and label\n",
    "        for event in ants:\n",
    "            starts += [float(event['start'])]\n",
    "            stops += [float(event['end'])]\n",
    "            if isinstance(event[label], (Tuple, List)):\n",
    "                # offset the labels by label_offset\n",
    "                label_id = 0\n",
    "                for i, x in enumerate(event[label][::-1]):\n",
    "                    label_id += label_offset ** i + int(x)\n",
    "            else:\n",
    "                # load label_id directly\n",
    "                label_id = int(event[label])\n",
    "            labels += [label_id]\"\"\"\n",
    "\n",
    "    # move to pd dataframe\n",
    "    gt_base = pd.DataFrame({\n",
    "        'video-id': vids,\n",
    "        't-start': starts,\n",
    "        't-end': stops,\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "    return gt_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(preds):\n",
    "        \"\"\"Evaluates a prediction file. For the detection task we measure the\n",
    "        interpolated mean average precision to measure the performance of a\n",
    "        method.\n",
    "        preds can be (1) a pd.DataFrame; or (2) a json file where the data will be loaded;\n",
    "        or (3) a python dict item with numpy arrays as the values\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(preds, Dict):\n",
    "            # move to pd dataframe\n",
    "            # did not check dtype here, can accept both numpy / pytorch tensors\n",
    "            preds = pd.DataFrame({\n",
    "                'video-id': preds['video-id'],\n",
    "                't-start': preds['t-start'].tolist(),\n",
    "                't-end': preds['t-end'].tolist(),\n",
    "                'label': preds['label'].tolist(),\n",
    "                'score': preds['score'].tolist()\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(pred_df,gt_df):\n",
    "    with open(\"/home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/data/cataract/data_1102.json\",\"r\") as f:\n",
    "        gt_json = json.load(f)\n",
    "    df_gt= pd.DataFrame(columns=[\"video_id\",\"gt_labels\"])\n",
    "    for k,v in gt_json.items():\n",
    "        if \"train\" in k:\n",
    "            continue\n",
    "        dur = v[\"last_time\"]\n",
    "        video_name = k.split(\".\")[0]\n",
    "        gt_labels = [0 for i in range(int(np.round(dur)))]\n",
    "        video_id = [k for i in range(int(np.round(dur)))]\n",
    "        df = pd.DataFrame(columns=[\"video_id\",\"gt_labels\"])\n",
    "        df[\"video_id\"] = video_id\n",
    "        df[\"gt_labels\"] = gt_labels\n",
    "        subset = gt_df[gt_df[\"video-id\"]==video_name]\n",
    "        \n",
    "        for index in subset.index:\n",
    "            start = int(np.round(subset.loc[index][\"t-start\"]))\n",
    "            end = int(np.round(subset.loc[index][\"t-end\"]))\n",
    "            label = subset.loc[index][\"label\"]\n",
    "            for i in range(start,end+1):\n",
    "                df.loc[i,\"gt_labels\"] = label+1\n",
    "        \n",
    "        df_gt = pd.concat([df_gt,df],ignore_index=True)    \n",
    "    df_pred = pd.DataFrame(columns=[\"video_id\",\"pred_labels\"])\n",
    "\n",
    "\n",
    "    for k,v in gt_json.items():\n",
    "        if \"train\" in k:\n",
    "            continue\n",
    "        video_name = k.split(\".\")[0]\n",
    "        dur = v[\"last_time\"]\n",
    "        gt_labels = [0 for i in range(int(np.round(dur)))]\n",
    "        video_id = [k for i in range(int(np.round(dur)))]\n",
    "        df = pd.DataFrame(columns=[\"video_id\",\"pred_labels\"])\n",
    "        df[\"video_id\"] = video_id\n",
    "        df[\"pred_labels\"] = gt_labels\n",
    "        subset = pred_df[pred_df[\"video-id\"]==video_name]\n",
    "        \n",
    "        for index in subset.index:\n",
    "            start = int(np.round(subset.loc[index][\"t-start\"]))\n",
    "            end = int(np.round(subset.loc[index][\"t-end\"]))\n",
    "            label = subset.loc[index][\"label\"]\n",
    "            for i in range(start,end+1):\n",
    "                if i>=len(df):\n",
    "                    continue\n",
    "                df.loc[i,\"pred_labels\"] = label+1\n",
    "        #print(df)\n",
    "        df_pred = pd.concat([df_pred,df],ignore_index=True)\n",
    "\n",
    "\n",
    "    return df_pred\n",
    "    \"\"\"\n",
    "    df_all =pd.concat([df_gt,df_pred[\"pred_labels\"]],axis=1)\n",
    "    acc = accuracy_score(df_all[\"gt_labels\"].to_list(),df_all[\"pred_labels\"].to_list())\n",
    "    f1 = f1_score(df_all[\"gt_labels\"].to_list(),df_all[\"pred_labels\"].to_list(),average=\"macro\")\n",
    "    recall = recall_score(df_all[\"gt_labels\"].to_list(),df_all[\"pred_labels\"].to_list(),average=\"macro\")\n",
    "    precision = precision_score(df_all[\"gt_labels\"].to_list(),df_all[\"pred_labels\"].to_list(),average=\"macro\")\n",
    "    df_pred.to_csv(\"df_pred.csv\",index=False)\n",
    "    df_gt.to_csv(\"df_gt.csv\",index=False)\n",
    "    print(\"accuracy under the threshold : \", acc,end=\"     \")\n",
    "    print(\"f1 score under the threshold : \", f1,end=\"     \")\n",
    "    print(\"precision score under the threshold : \", precision,end=\"     \")\n",
    "    print(\"recall score under the threshold : \", recall)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_label(pred_df,mid_index,threshold=0.22):\n",
    "    df = pred_df[pred_df[\"score\"]>threshold]\n",
    "    label = 0\n",
    "    score = threshold\n",
    "    s = mid_index[0]\n",
    "    e = mid_index[1]\n",
    "    #filter df\n",
    "    if len(df) == 0:\n",
    "        for i in range(len(pred_df)):\n",
    "            if pred_df.iloc[i][\"t-start\"]<=e and pred_df.iloc[i][\"t-end\"]>=s:\n",
    "                label = 0\n",
    "                score = pred_df.iloc[i][\"score\"]\n",
    "                break\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i][\"t-start\"]<=e and df.iloc[i][\"t-end\"]>=s:\n",
    "            label = df.iloc[i][\"label\"]\n",
    "            score = df.iloc[i][\"score\"]\n",
    "            break\n",
    "    return label,score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_middle_label(pred_df,mid_index,threshold=0.22):\\n    df = pred_df[pred_df[\"score\"]>threshold]\\n    label = 0\\n    s = mid_index[0]\\n    e = mid_index[1]\\n    #filter df\\n    for i in range(len(df)):\\n        if mid_index>=df.iloc[i][\"t-start\"] and mid_index <= df.iloc[i][\"t-end\"]:\\n            label = df.iloc[i][\"label\"]\\n            break\\n    return label'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_middle_label(pred_df,mid_index,threshold=0.22):\n",
    "    df = pred_df[pred_df[\"score\"]>threshold]\n",
    "    label = 0\n",
    "    s = mid_index[0]\n",
    "    e = mid_index[1]\n",
    "    #filter df\n",
    "    for i in range(len(df)):\n",
    "        if mid_index>=df.iloc[i][\"t-start\"] and mid_index <= df.iloc[i][\"t-end\"]:\n",
    "            label = df.iloc[i][\"label\"]\n",
    "            break\n",
    "    return label\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deprecated\n",
    "def mirror_feature(inputs,reversed_inputs,filled_inputs,num_fill):\n",
    "    feat = inputs[\"feats\"]\n",
    "    feat_flipped = torch.from_numpy(reversed_inputs)\n",
    "    feat_flipped = feat_flipped.transpose(0, 1)\n",
    "    if num_fill>0:\n",
    "        feat_fill = np.repeat(filled_inputs,num_fill,axis=0)\n",
    "        \n",
    "        feat_fill = torch.from_numpy(feat_fill)\n",
    "        feat_fill = feat_fill.transpose(0, 1)\n",
    "        feat_mirrored = torch.concat((feat, feat_fill,feat_flipped), dim=1)\n",
    "        if feat_mirrored.size(1)>1024:\n",
    "            center = feat_mirrored.size(1)//2\n",
    "            start_index = center-512\n",
    "            end_index = center+512\n",
    "            feat_mirrored = feat_mirrored[:, start_index:end_index]\n",
    "            inputs[\"feats\"] = feat_mirrored\n",
    "            inputs['duration'] = 1024\n",
    "            return inputs\n",
    "        inputs[\"feats\"] = feat_mirrored\n",
    "        inputs['duration'] = inputs['duration']*2+num_fill\n",
    "        \n",
    "    else:\n",
    "        feat_mirrored = torch.concat((feat, feat_fill,feat_flipped), dim=1)\n",
    "        inputs[\"feats\"] = feat_mirrored\n",
    "        inputs['duration'] = inputs['duration']*2\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_feature(inputs,reversed_inputs,filled_inputs,num_fill):\n",
    "    feat = inputs[\"feats\"]\n",
    "    feat_flipped = torch.from_numpy(reversed_inputs)\n",
    "    feat_flipped = feat_flipped.transpose(0, 1)\n",
    "    if num_fill>0:\n",
    "        feat_fill = np.repeat(filled_inputs,num_fill,axis=0)\n",
    "        \n",
    "        feat_fill = torch.from_numpy(feat_fill)\n",
    "        feat_fill = feat_fill.transpose(0, 1)\n",
    "        feat_mirrored = torch.concat((feat, feat_fill,feat_flipped), dim=1)\n",
    "        inputs[\"feats\"] = feat_mirrored\n",
    "        inputs['duration'] = inputs['duration']*2+num_fill\n",
    "        ratio = inputs[\"duration\"]//512+1\n",
    "        inputs[\"feats\"] = feat_mirrored[:,::ratio]\n",
    "        inputs['duration'] = len(inputs[\"feats\"])\n",
    "    else:\n",
    "        feat_mirrored = torch.concat((feat,feat_flipped), dim=1)\n",
    "        inputs[\"feats\"] = feat_mirrored\n",
    "        inputs['duration'] = inputs['duration']*2\n",
    "        ratio = inputs[\"duration\"]//512+1\n",
    "        inputs[\"feats\"] = feat_mirrored[:,::ratio]\n",
    "        inputs['duration'] = len(inputs[\"feats\"])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_feature(inputs,filled_inputs,num_fill):\n",
    "    feat = inputs[\"feats\"]\n",
    "    feat_fill = np.repeat(filled_inputs,num_fill,axis=0)\n",
    "    feat_fill = torch.from_numpy(feat_fill)\n",
    "    feat_fill = feat_fill.transpose(0, 1)\n",
    "    feat_filled = torch.concat((feat, feat_fill), dim=1)\n",
    "    inputs[\"feats\"] = feat_filled\n",
    "    inputs['duration'] = inputs['duration']+num_fill\n",
    "    ratio = inputs[\"duration\"]//512+1\n",
    "    inputs[\"feats\"] = feat_filled[:,::ratio]\n",
    "    inputs['duration'] = len(inputs[\"feats\"])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deprecated\n",
    "def fill_feature(inputs,fill_n_times=3):\n",
    "        #return the mirrored inputs, e.g (2304,100) -> (2304,200)\n",
    "    feat = inputs[\"feats\"]\n",
    "    feat_fill = np.repeat(filled_inputs,num_fill,axis=0)\n",
    "    feat_fill = torch.from_numpy(feat_fill)\n",
    "    feat_fill = feat_fill.transpose(0, 1)\n",
    "    feat_mirrored = torch.concat((feat, feat_fill), dim=1)\n",
    "    \"\"\"if feat_mirrored.size(1)>1024:\n",
    "            center = feat_mirrored.size(1)//2\n",
    "            start_index = center-512\n",
    "            end_index = center+512\n",
    "            feat_mirrored = feat_mirrored[:, start_index:end_index]\n",
    "            inputs[\"feats\"] = feat_mirrored\n",
    "            inputs['duration'] = 1024\n",
    "            return inputs\"\"\"\n",
    "    inputs[\"feats\"] = feat_mirrored\n",
    "    inputs['duration'] = inputs['duration']+num_fill\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction configs\n",
    "args = parse_args()\n",
    "cfg = load_config(args)\n",
    "cfg.USED_GPU = 4 #make sure it is same as device\n",
    "vid_path = \"/home/lxj/project/surgplan/LUO/cataract_test_video/test03.mp4\"\n",
    "\n",
    "#tridet_cfg = load_tridet_config(\"/data/disk/LUO/test_only/TriDet/configs/cataract_slowfast.yaml\")\n",
    "\n",
    "#ckpt_file = '/data/disk/LUO/epoch_110_best.pth.tar'\n",
    "\n",
    "tridet_cfg = load_tridet_config(\"/home/lxj/project/surgplan/LUO/test_only/TriDet/configs/cataract_slowfast_0219.yaml\")\n",
    "ckpt_file = '/home/lxj/project/surgplan/LUO/test_only/TriDet/ckpt/cataract_slowfast_0219_redivide/epoch_100.pth.tar'\n",
    "topk=-1\n",
    "tridet_cfg['model']['test_cfg']['max_seg_num'] = topk\n",
    "print_freq = 10\n",
    "save_only = False\n",
    "\n",
    "# fix the random seeds (this will fix everything)\n",
    "_ = fix_random_seed(0, include_cuda=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "\n",
    "device = \"cuda:7\"\n",
    "cap = cv2.VideoCapture(vid_path)\n",
    "sample_height = 256\n",
    "sample_width = 256\n",
    "count = 0\n",
    "seq_length = 32\n",
    "queue = deque(maxlen=64)\n",
    "ret = True\n",
    "frame_wise_feature = None\n",
    "extract_model = build_model(cfg).to(device)\n",
    "print(\"loading feature extraction model\")\n",
    "extract_checkpoint = torch.load(\"/data/disk/LUO/slowfast/feature_extract/checkpoints/checkpoint_epoch_00130.pyth\",map_location=device)\n",
    "extract_model.load_state_dict(extract_checkpoint['model_state'])\n",
    "del extract_checkpoint\n",
    "idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "current_db = dict_db[idx] #current test file json\n",
    "count_2 = 0 #count after queue is full\n",
    "num_fill = 32\n",
    "# load tridet model\n",
    "model = make_meta_arch(tridet_cfg['model_name'], **tridet_cfg['model'])\n",
    "# not ideal for multi GPU training, ok for now\n",
    "model = nn.DataParallel(model, device_ids=tridet_cfg['devices'])\n",
    "print(\"=> loading checkpoint '{}'\".format(ckpt_file))\n",
    "# load ckpt, reset epoch / best rmse\n",
    "checkpoint = torch.load(\n",
    "    ckpt_file,\n",
    "    map_location=lambda storage, loc: storage.cuda(tridet_cfg['devices'][0])\n",
    ")\n",
    "\n",
    "# load ema model instead\n",
    "print(\"Loading from EMA model ...\")\n",
    "model.load_state_dict(checkpoint['state_dict_ema'])\n",
    "del checkpoint\n",
    "pure_pred_list = []\n",
    "fill_pred_list = []\n",
    "pred_list = []\n",
    "start = datetime.datetime.now()\n",
    "while ret:\n",
    "    #print(\"count: \",count)\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"finished\")\n",
    "        break\n",
    "    height, width = frame.shape[:2]\n",
    "    frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "    queue.append(frame)\n",
    "    if count<64:\n",
    "        count+=1\n",
    "        continue\n",
    "    else:\n",
    "        frames = np.stack(queue, axis=0)\n",
    "        frames = frames[::2,:,:,:]\n",
    "        reversed_frames = np.flip(frames, axis=0)\n",
    "        reversed_frames = reversed_frames.copy()\n",
    "        filled_frames = np.expand_dims(frame, axis=0)\n",
    "        filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "        #print(frames.shape)\n",
    "        #print(reversed_frames.shape)\n",
    "        #print(filled_frames.shape)\n",
    "        frames = pre_process_frame(frames)\n",
    "        reversed_frames = pre_process_frame(reversed_frames)\n",
    "        filled_frames = pre_process_frame(filled_frames)\n",
    "        \n",
    "        frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "        frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "        frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "        reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "        reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "        reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "        filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "        filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "        filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "        if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "            cur_second = count//30\n",
    "            print(\"current second: \",cur_second+2)\n",
    "            if frame_wise_feature is None:\n",
    "                frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                #print(test(cfg,frame_list))\n",
    "            else:\n",
    "                #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                cur_feature = test(extract_model,cfg,frame_list)\n",
    "                reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                #print(\"cur_feature \",cur_feature.shape)\n",
    "                frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "\n",
    "                filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                #print(reversed_frame_wise_feature.shape)\n",
    "                #print(filled_frame_wise_feature.shape)\n",
    "                #print(frame_wise_feture.shape)\n",
    "                #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "            \n",
    "            \n",
    "            #transfer input frame_wise_features into dictionary\n",
    "            inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "            results = valid_one_epoch([inputs],model=model)\n",
    "            df_1 = to_df(results)\n",
    "            pred_label,score = get_middle_label(df_1,[cur_second-2,cur_second],threshold=0.15)\n",
    "            pure_pred_list.append(pred_label)\n",
    "            print(\"no mirror predicted label: \",pred_label,\" score:\",score)\n",
    "            #ret = False\n",
    "            #inference\n",
    "\n",
    "            mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "            results = valid_one_epoch([mirror_features],model=model)\n",
    "            df = to_df(results)\n",
    "            if inputs[\"feats\"].size(1) >= 1024:\n",
    "                pred_label,score = get_middle_label(df,[512-num_fill//2,512+num_fill//2],0.15)\n",
    "            else:\n",
    "                pred_label,score = get_middle_label(df,[cur_second+num_fill-2,cur_second+num_fill],threshold=0.15)\n",
    "\n",
    "            print(\"mirror predicted label: \",pred_label,\" score:\",score)\n",
    "            print()\n",
    "            pred_list.append(pred_label)\n",
    "        count+=1\n",
    "        count_2 +=1 \n",
    "end = datetime.datetime.now()\n",
    "\n",
    "print(\"total time: \", (end-start).seconds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "gt = pd.read_csv(\"/home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/df_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3652694610778443"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug only\n",
    "accuracy_score(gt[gt[\"video_id\"]==\"test03.mp4\"][\"gt_labels\"][-len(pred_list):],pure_pred_list[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "#Feature extraction configs\n",
    "args = parse_args()\n",
    "cfg = load_config(args)\n",
    "cfg.USED_GPU = 1 #make sure it is same as device\n",
    "\n",
    "#tridet_cfg = load_tridet_config(\"/data/disk/LUO/test_only/TriDet/configs/cataract_slowfast.yaml\")\n",
    "#ckpt_file = '/data/disk/LUO/epoch_110_best.pth.tar'\n",
    "\n",
    "tridet_cfg = load_tridet_config(\"/home/lxj/project/surgplan/LUO/test_only/TriDet/configs/cataract_slowfast_reverse.yaml\")\n",
    "ckpt_file = '/home/lxj/project/surgplan/LUO/test_only/TriDet/ckpt/cataract_slowfast_reverse_reverse/epoch_080.pth.tar'\n",
    "\n",
    "topk=-1\n",
    "print_freq = 10\n",
    "save_only = False\n",
    "\n",
    "# fix the random seeds (this will fix everything)\n",
    "_ = fix_random_seed(0, include_cuda=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Feature Extraction Model ...\n",
      "=> loading checkpoint '/home/lxj/project/surgplan/LUO/test_only/TriDet/ckpt/cataract_slowfast_0219_redivide/epoch_100.pth.tar'\n",
      "loading finish\n",
      "Loading from EMA model ...\n",
      "loading finish\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:4\"\n",
    "extract_model = build_model(cfg).to(device)\n",
    "extract_checkpoint = torch.load(\"/home/lxj/project/surgplan/LUO/slowfast/feature_extract/checkpoints/checkpoint_epoch_00130.pyth\",map_location=device)\n",
    "print(\"Loading from Feature Extraction Model ...\")\n",
    "extract_model.load_state_dict(extract_checkpoint['model_state'])\n",
    "del extract_checkpoint\n",
    "model = make_meta_arch(tridet_cfg['model_name'], **tridet_cfg['model'])\n",
    "model = nn.DataParallel(model, device_ids=tridet_cfg['devices'])\n",
    "print(\"=> loading checkpoint '{}'\".format(ckpt_file))\n",
    "checkpoint = torch.load(\n",
    "    ckpt_file,\n",
    "    map_location=lambda storage, loc: storage.cuda(tridet_cfg['devices'][0])\n",
    ")\n",
    "print(\"loading finish\")\n",
    "# load ema model instead\n",
    "print(\"Loading from EMA model ...\")\n",
    "model.load_state_dict(checkpoint['state_dict_ema'])\n",
    "del checkpoint\n",
    "print(\"loading finish\")\n",
    "gt = pd.read_csv(\"/home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/df_gt.csv\")\n",
    "dir_name = \"/home/lxj/project/surgplan/LUO/cataract_test_video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pure(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:0\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=64)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<64:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = frames[::2,:,:,:]\n",
    "            #reversed_frames = np.flip(frames, axis=0)\n",
    "            #reversed_frames = reversed_frames.copy()\n",
    "            #filled_frames = np.expand_dims(frame, axis=0)\n",
    "            #filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "            #print(frames.shape)\n",
    "            #print(reversed_frames.shape)\n",
    "            #print(filled_frames.shape)\n",
    "            frames = pre_process_frame(frames)\n",
    "            #reversed_frames = pre_process_frame(reversed_frames)\n",
    "            #filled_frames = pre_process_frame(filled_frames)\n",
    "            \n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "            #reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "            #reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            #reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "            #filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "            #filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            #filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    #reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    #reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    #reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "\n",
    "                    #filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(reversed_frame_wise_feature.shape)\n",
    "                    #print(filled_frame_wise_feature.shape)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                \n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #inference\n",
    "                #mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "                if inputs[\"feats\"].size(1) >= 1024:\n",
    "                    inputs[\"feats\"] = inputs[\"feats\"][:, -1024:]\n",
    "                    inputs['duration'] = 1024\n",
    "                    results = valid_one_epoch([inputs],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[1022,1024],threshold)\n",
    "                else:\n",
    "                    results = valid_one_epoch([inputs],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[cur_second-2,cur_second],threshold=threshold)\n",
    "\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fill(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:0\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=64)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<64:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = frames[::2,:,:,:]\n",
    "            #reversed_frames = np.flip(frames, axis=0)\n",
    "            #reversed_frames = reversed_frames.copy()\n",
    "            filled_frames = np.expand_dims(frame, axis=0)\n",
    "            filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "            #print(frames.shape)\n",
    "            #print(reversed_frames.shape)\n",
    "            #print(filled_frames.shape)\n",
    "            frames = pre_process_frame(frames)\n",
    "            #reversed_frames = pre_process_frame(reversed_frames)\n",
    "            filled_frames = pre_process_frame(filled_frames)\n",
    "            \n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "            #reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "            #reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            #reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "            filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "            filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    #reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    #reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    #reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(reversed_frame_wise_feature.shape)\n",
    "                    #print(filled_frame_wise_feature.shape)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                \n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #inference\n",
    "                #mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "                filled_inputs = fill_feature(inputs,filled_frame_wise_feature,num_fill)\n",
    "                if filled_inputs[\"feats\"].size(1) >= 512:\n",
    "                    filled_inputs[\"feats\"] = filled_inputs[\"feats\"][:, -512:]\n",
    "                    filled_inputs['duration'] = 512\n",
    "                    results = valid_one_epoch([filled_inputs],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[510,512],threshold)\n",
    "                else:\n",
    "                    results = valid_one_epoch([filled_inputs],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[cur_second-2,cur_second],threshold=threshold)\n",
    "\n",
    "\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_mirror(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:4\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=64)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<64:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = frames[::2,:,:,:]\n",
    "            reversed_frames = np.flip(frames, axis=0)\n",
    "            reversed_frames = reversed_frames.copy()\n",
    "            filled_frames = np.expand_dims(frame, axis=0)\n",
    "            filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "            #print(frames.shape)\n",
    "            #print(reversed_frames.shape)\n",
    "            #print(filled_frames.shape)\n",
    "            frames = pre_process_frame(frames)\n",
    "            reversed_frames = pre_process_frame(reversed_frames)\n",
    "            filled_frames = pre_process_frame(filled_frames)\n",
    "            \n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "            reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "            reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "            filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "            filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    filled_frame_wise_feature = None\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "                    filled_frame_wise_feature = None\n",
    "                    #print(reversed_frame_wise_feature.shape)\n",
    "                    #print(filled_frame_wise_feature.shape)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                \n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #inference\n",
    "                mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "                #filled_inputs = fill_feature(inputs,filled_frame_wise_feature,num_fill)\n",
    "                if mirror_features[\"feats\"].size(1) >= 512:\n",
    "                    mirror_features[\"feats\"] = mirror_features[\"feats\"][:, -512:]\n",
    "                    mirror_features['duration'] = 512\n",
    "                    results = valid_one_epoch([mirror_features],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[255,257],threshold)\n",
    "                else:\n",
    "                    results = valid_one_epoch([mirror_features],model=model)\n",
    "                    df = to_df(results)\n",
    "                    pred_label,score = get_middle_label(df,[cur_second-2,cur_second],threshold=threshold)\n",
    "\n",
    "\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/home/lxj/project/surgplan/LUO/cataract_test_video\"):\n",
    "    main_pure(i,cur_time,threshold=0.16,num_fill=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cur_time \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(cur_time)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cur_time)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "print(cur_time)\n",
    "for i in os.listdir(\"/home/lxj/project/surgplan/LUO/cataract_test_video\"):\n",
    "    main_fill(i,cur_time,threshold=0.16,num_fill=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-02-27-08-44-57_result mirror\n",
    "# /home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/2024-02-27-06-57-01_result fill\n",
    "# /home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/2024-02-27-01-45-55_result pure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27-08-44-57_result\n",
      "Eval video:  test13.mp4  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time:  283\n",
      "accuracy for vid:  test13.mp4  is :  0.3194945848375451\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  549\n",
      "accuracy for vid:  test07.mp4  is :  0.45375722543352603\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  244\n",
      "accuracy for vid:  test15.mp4  is :  0.42857142857142855\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  223\n",
      "accuracy for vid:  test05.mp4  is :  0.36616702355460384\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  265\n",
      "accuracy for vid:  test11.mp4  is :  0.390625\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  337\n",
      "accuracy for vid:  test09.mp4  is :  0.39285714285714285\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  295\n",
      "accuracy for vid:  test25.mp4  is :  0.32767402376910015\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  437\n",
      "accuracy for vid:  test18.mp4  is :  0.3199426111908178\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  420\n",
      "accuracy for vid:  test19.mp4  is :  0.3625170998632011\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  299\n",
      "accuracy for vid:  test20.mp4  is :  0.3527204502814259\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  329\n",
      "accuracy for vid:  test10.mp4  is :  0.48853615520282184\n",
      "Eval video:  test01.mp4  ...\n",
      "total time:  427\n",
      "accuracy for vid:  test01.mp4  is :  0.2912234042553192\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  222\n",
      "accuracy for vid:  test14.mp4  is :  0.5419847328244275\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  283\n",
      "accuracy for vid:  test03.mp4  is :  0.4930139720558882\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  279\n",
      "accuracy for vid:  test24.mp4  is :  0.39805825242718446\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  335\n",
      "accuracy for vid:  test16.mp4  is :  0.34508076358296624\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  252\n",
      "accuracy for vid:  test23.mp4  is :  0.5547024952015355\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  193\n",
      "accuracy for vid:  test12.mp4  is :  0.44358974358974357\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  227\n",
      "accuracy for vid:  test21.mp4  is :  0.3736951983298539\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  250\n",
      "accuracy for vid:  test17.mp4  is :  0.3568627450980392\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  893\n",
      "accuracy for vid:  test02.mp4  is :  0.3460916442048518\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  241\n",
      "accuracy for vid:  test22.mp4  is :  0.3516260162601626\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  208\n",
      "accuracy for vid:  test08.mp4  is :  0.5226244343891403\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  280\n",
      "accuracy for vid:  test06.mp4  is :  0.5336879432624113\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  238\n",
      "accuracy for vid:  test04.mp4  is :  0.45228215767634855\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "print(cur_time)\n",
    "for i in os.listdir(\"/home/lxj/project/surgplan/LUO/cataract_test_video\"):\n",
    "    main_mirror(i,cur_time,threshold=0.16,num_fill=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:4\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=64)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<64:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = frames[::2,:,:,:]\n",
    "            reversed_frames = np.flip(frames, axis=0)\n",
    "            reversed_frames = reversed_frames.copy()\n",
    "            filled_frames = np.expand_dims(frame, axis=0)\n",
    "            filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "            #print(frames.shape)\n",
    "            #print(reversed_frames.shape)\n",
    "            #print(filled_frames.shape)\n",
    "            frames = pre_process_frame(frames)\n",
    "            reversed_frames = pre_process_frame(reversed_frames)\n",
    "            filled_frames = pre_process_frame(filled_frames)\n",
    "            \n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "            reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "            reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "            filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "            filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(reversed_frame_wise_feature.shape)\n",
    "                    #print(filled_frame_wise_feature.shape)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #inference\n",
    "                mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "                results = valid_one_epoch([mirror_features],model=model)\n",
    "                df = to_df(results)\n",
    "                if mirror_features[\"feats\"].size(1) >= 1024:\n",
    "                    pred_label,score = get_middle_label(df,[512-num_fill//2,512+num_fill//2],threshold)\n",
    "                else:\n",
    "                    pred_label,score = get_middle_label(df,[cur_second+num_fill-2,cur_second+num_fill],threshold=threshold)\n",
    "\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.18,num_fill=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "total time:  545\n",
      "accuracy for vid:  test01.mp4  is :  0.6329787234042553\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1306\n",
      "accuracy for vid:  test02.mp4  is :  0.505121293800539\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  366\n",
      "accuracy for vid:  test03.mp4  is :  0.812375249500998\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  341\n",
      "accuracy for vid:  test04.mp4  is :  0.7572614107883817\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  330\n",
      "accuracy for vid:  test05.mp4  is :  0.69593147751606\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  310\n",
      "accuracy for vid:  test06.mp4  is :  0.725177304964539\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  490\n",
      "accuracy for vid:  test07.mp4  is :  0.571290944123314\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  212\n",
      "accuracy for vid:  test08.mp4  is :  0.744343891402715\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  309\n",
      "accuracy for vid:  test09.mp4  is :  0.7732919254658385\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  272\n",
      "accuracy for vid:  test10.mp4  is :  0.7125220458553791\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  245\n",
      "accuracy for vid:  test11.mp4  is :  0.685546875\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  192\n",
      "accuracy for vid:  test12.mp4  is :  0.7923076923076923\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  261\n",
      "accuracy for vid:  test13.mp4  is :  0.7274368231046932\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  189\n",
      "accuracy for vid:  test14.mp4  is :  0.7099236641221374\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  236\n",
      "accuracy for vid:  test15.mp4  is :  0.7577639751552795\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  322\n",
      "accuracy for vid:  test16.mp4  is :  0.7004405286343612\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  250\n",
      "accuracy for vid:  test17.mp4  is :  0.6803921568627451\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  340\n",
      "accuracy for vid:  test18.mp4  is :  0.7130559540889526\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  361\n",
      "accuracy for vid:  test19.mp4  is :  0.7058823529411765\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  265\n",
      "accuracy for vid:  test20.mp4  is :  0.7467166979362101\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  233\n",
      "accuracy for vid:  test21.mp4  is :  0.755741127348643\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  245\n",
      "accuracy for vid:  test22.mp4  is :  0.6686991869918699\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  255\n",
      "accuracy for vid:  test23.mp4  is :  0.8214971209213052\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  252\n",
      "accuracy for vid:  test24.mp4  is :  0.7669902912621359\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  296\n",
      "accuracy for vid:  test25.mp4  is :  0.6706281833616299\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Feature Extraction Model ...\n",
      "=> loading checkpoint '/data/disk/LUO/test_only/TriDet/ckpt/cataract_slowfast_reverse_reverse/epoch_050.pth.tar'\n",
      "loading finish\n",
      "Loading from EMA model ...\n",
      "loading finish\n"
     ]
    }
   ],
   "source": [
    "ckpt_file = '/data/disk/LUO/test_only/TriDet/ckpt/cataract_slowfast_reverse_reverse/epoch_050.pth.tar'\n",
    "\n",
    "extract_model = build_model(cfg).to(device)\n",
    "extract_checkpoint = torch.load(\"/data/disk/LUO/slowfast/feature_extract/checkpoints/checkpoint_epoch_00130.pyth\",map_location=device)\n",
    "print(\"Loading from Feature Extraction Model ...\")\n",
    "extract_model.load_state_dict(extract_checkpoint['model_state'])\n",
    "del extract_checkpoint\n",
    "model = make_meta_arch(tridet_cfg['model_name'], **tridet_cfg['model'])\n",
    "model = nn.DataParallel(model, device_ids=tridet_cfg['devices'])\n",
    "print(\"=> loading checkpoint '{}'\".format(ckpt_file))\n",
    "checkpoint = torch.load(\n",
    "    ckpt_file,\n",
    "    map_location=lambda storage, loc: storage.cuda(tridet_cfg['devices'][0])\n",
    ")\n",
    "print(\"loading finish\")\n",
    "# load ema model instead\n",
    "print(\"Loading from EMA model ...\")\n",
    "model.load_state_dict(checkpoint['state_dict_ema'])\n",
    "del checkpoint\n",
    "print(\"loading finish\")\n",
    "gt = pd.read_csv(\"/data/disk/LUO/test_only/r_tridet/TriDet/df_gt.csv\")\n",
    "dir_name = \"/data/disk/LUO/cataract_test_video\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "total time:  434\n",
      "accuracy for vid:  test01.mp4  is :  0.6742021276595744\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1153\n",
      "accuracy for vid:  test02.mp4  is :  0.5266846361185984\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  318\n",
      "accuracy for vid:  test03.mp4  is :  0.7405189620758483\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  310\n",
      "accuracy for vid:  test04.mp4  is :  0.7302904564315352\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  296\n",
      "accuracy for vid:  test05.mp4  is :  0.69593147751606\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  366\n",
      "accuracy for vid:  test06.mp4  is :  0.6985815602836879\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  667\n",
      "accuracy for vid:  test07.mp4  is :  0.546242774566474\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  284\n",
      "accuracy for vid:  test08.mp4  is :  0.7579185520361991\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  402\n",
      "accuracy for vid:  test09.mp4  is :  0.7468944099378882\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  349\n",
      "accuracy for vid:  test10.mp4  is :  0.691358024691358\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  317\n",
      "accuracy for vid:  test11.mp4  is :  0.69140625\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  241\n",
      "accuracy for vid:  test12.mp4  is :  0.7153846153846154\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  340\n",
      "accuracy for vid:  test13.mp4  is :  0.7184115523465704\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  246\n",
      "accuracy for vid:  test14.mp4  is :  0.6692111959287532\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  302\n",
      "accuracy for vid:  test15.mp4  is :  0.6728778467908902\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  431\n",
      "accuracy for vid:  test16.mp4  is :  0.6284875183553598\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  319\n",
      "accuracy for vid:  test17.mp4  is :  0.6411764705882353\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  431\n",
      "accuracy for vid:  test18.mp4  is :  0.6757532281205165\n",
      "Eval video:  test19.mp4  ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(cur_time)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/disk/LUO/cataract_test_video\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcur_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.135\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 29\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(vid, log_folder, threshold, num_fill)\u001b[0m\n\u001b[1;32m     25\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ret:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#print(\"count: \",count)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     ret,frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.135,num_fill=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  299\n",
      "accuracy for vid:  test01.mp4  is :  0.7184594953519257\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  739\n",
      "accuracy for vid:  test02.mp4  is :  0.5129310344827587\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  201\n",
      "accuracy for vid:  test03.mp4  is :  0.8449304174950298\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  188\n",
      "accuracy for vid:  test04.mp4  is :  0.7784679089026915\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  184\n",
      "accuracy for vid:  test05.mp4  is :  0.7547974413646056\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  231\n",
      "accuracy for vid:  test06.mp4  is :  0.6831858407079646\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  435\n",
      "accuracy for vid:  test07.mp4  is :  0.5663461538461538\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  185\n",
      "accuracy for vid:  test08.mp4  is :  0.7539503386004515\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  268\n",
      "accuracy for vid:  test09.mp4  is :  0.7286821705426356\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  241\n",
      "accuracy for vid:  test10.mp4  is :  0.7341549295774648\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  221\n",
      "accuracy for vid:  test11.mp4  is :  0.7524366471734892\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  164\n",
      "accuracy for vid:  test12.mp4  is :  0.7979539641943734\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  236\n",
      "accuracy for vid:  test13.mp4  is :  0.8057553956834532\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  164\n",
      "accuracy for vid:  test14.mp4  is :  0.7563451776649747\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  206\n",
      "accuracy for vid:  test15.mp4  is :  0.7706611570247934\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  280\n",
      "accuracy for vid:  test16.mp4  is :  0.6862170087976539\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  218\n",
      "accuracy for vid:  test17.mp4  is :  0.6927592954990215\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  292\n",
      "accuracy for vid:  test18.mp4  is :  0.7010014306151645\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  302\n",
      "accuracy for vid:  test19.mp4  is :  0.73224043715847\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  221\n",
      "accuracy for vid:  test20.mp4  is :  0.799625468164794\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  189\n",
      "accuracy for vid:  test21.mp4  is :  0.8083333333333333\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  201\n",
      "accuracy for vid:  test22.mp4  is :  0.7200811359026369\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  202\n",
      "accuracy for vid:  test23.mp4  is :  0.8199233716475096\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  209\n",
      "accuracy for vid:  test24.mp4  is :  0.7751937984496124\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  241\n",
      "accuracy for vid:  test25.mp4  is :  0.6694915254237288\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  314\n",
      "accuracy for vid:  test01.mp4  is :  0.7237715803452855\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  789\n",
      "accuracy for vid:  test02.mp4  is :  0.5021551724137931\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  205\n",
      "accuracy for vid:  test03.mp4  is :  0.8608349900596421\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  203\n",
      "accuracy for vid:  test04.mp4  is :  0.7950310559006211\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  187\n",
      "accuracy for vid:  test05.mp4  is :  0.7611940298507462\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  239\n",
      "accuracy for vid:  test06.mp4  is :  0.7150442477876107\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  422\n",
      "accuracy for vid:  test07.mp4  is :  0.5682692307692307\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  179\n",
      "accuracy for vid:  test08.mp4  is :  0.8103837471783296\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  269\n",
      "accuracy for vid:  test09.mp4  is :  0.737984496124031\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  236\n",
      "accuracy for vid:  test10.mp4  is :  0.7411971830985915\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  212\n",
      "accuracy for vid:  test11.mp4  is :  0.7738791423001949\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  159\n",
      "accuracy for vid:  test12.mp4  is :  0.8388746803069054\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  228\n",
      "accuracy for vid:  test13.mp4  is :  0.8093525179856115\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  158\n",
      "accuracy for vid:  test14.mp4  is :  0.7944162436548223\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  197\n",
      "accuracy for vid:  test15.mp4  is :  0.7582644628099173\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  302\n",
      "accuracy for vid:  test16.mp4  is :  0.7052785923753666\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  213\n",
      "accuracy for vid:  test17.mp4  is :  0.7299412915851272\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  280\n",
      "accuracy for vid:  test18.mp4  is :  0.7167381974248928\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  290\n",
      "accuracy for vid:  test19.mp4  is :  0.75\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  207\n",
      "accuracy for vid:  test20.mp4  is :  0.7827715355805244\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  195\n",
      "accuracy for vid:  test21.mp4  is :  0.8354166666666667\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  198\n",
      "accuracy for vid:  test22.mp4  is :  0.7281947261663286\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  213\n",
      "accuracy for vid:  test23.mp4  is :  0.8275862068965517\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  211\n",
      "accuracy for vid:  test24.mp4  is :  0.7790697674418605\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  234\n",
      "accuracy for vid:  test25.mp4  is :  0.6983050847457627\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "total time:  724\n",
      "accuracy for vid:  test01.mp4  is :  0.6595744680851063\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1720\n",
      "accuracy for vid:  test02.mp4  is :  0.5202156334231806\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  515\n",
      "accuracy for vid:  test03.mp4  is :  0.8303393213572854\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  484\n",
      "accuracy for vid:  test04.mp4  is :  0.7883817427385892\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  454\n",
      "accuracy for vid:  test05.mp4  is :  0.7044967880085653\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  553\n",
      "accuracy for vid:  test06.mp4  is :  0.75\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  1042\n",
      "accuracy for vid:  test07.mp4  is :  0.603082851637765\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  450\n",
      "accuracy for vid:  test08.mp4  is :  0.7782805429864253\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  643\n",
      "accuracy for vid:  test09.mp4  is :  0.7748447204968945\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  593\n",
      "accuracy for vid:  test10.mp4  is :  0.763668430335097\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  500\n",
      "accuracy for vid:  test11.mp4  is :  0.6875\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  375\n",
      "accuracy for vid:  test12.mp4  is :  0.8051282051282052\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  549\n",
      "accuracy for vid:  test13.mp4  is :  0.7184115523465704\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  375\n",
      "accuracy for vid:  test14.mp4  is :  0.7506361323155216\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  466\n",
      "accuracy for vid:  test15.mp4  is :  0.7329192546583851\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  695\n",
      "accuracy for vid:  test16.mp4  is :  0.7224669603524229\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  535\n",
      "accuracy for vid:  test17.mp4  is :  0.707843137254902\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  789\n",
      "accuracy for vid:  test18.mp4  is :  0.7116212338593975\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  762\n",
      "accuracy for vid:  test19.mp4  is :  0.719562243502052\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  561\n",
      "accuracy for vid:  test20.mp4  is :  0.7692307692307693\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  480\n",
      "accuracy for vid:  test21.mp4  is :  0.7661795407098121\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  505\n",
      "accuracy for vid:  test22.mp4  is :  0.6910569105691057\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  509\n",
      "accuracy for vid:  test23.mp4  is :  0.8426103646833013\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  482\n",
      "accuracy for vid:  test24.mp4  is :  0.7766990291262136\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  553\n",
      "accuracy for vid:  test25.mp4  is :  0.7011884550084889\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  277\n",
      "accuracy for vid:  test01.mp4  is :  0.6759628154050464\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  675\n",
      "accuracy for vid:  test02.mp4  is :  0.5\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  185\n",
      "accuracy for vid:  test03.mp4  is :  0.8588469184890656\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  174\n",
      "accuracy for vid:  test04.mp4  is :  0.7991718426501035\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  174\n",
      "accuracy for vid:  test05.mp4  is :  0.7718550106609808\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  206\n",
      "accuracy for vid:  test06.mp4  is :  0.7044247787610619\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  368\n",
      "accuracy for vid:  test07.mp4  is :  0.573076923076923\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  166\n",
      "accuracy for vid:  test08.mp4  is :  0.7900677200902935\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  235\n",
      "accuracy for vid:  test09.mp4  is :  0.7488372093023256\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  200\n",
      "accuracy for vid:  test10.mp4  is :  0.7429577464788732\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  186\n",
      "accuracy for vid:  test11.mp4  is :  0.7660818713450293\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  132\n",
      "accuracy for vid:  test12.mp4  is :  0.8312020460358056\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  208\n",
      "accuracy for vid:  test13.mp4  is :  0.802158273381295\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  142\n",
      "accuracy for vid:  test14.mp4  is :  0.7817258883248731\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  170\n",
      "accuracy for vid:  test15.mp4  is :  0.762396694214876\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  245\n",
      "accuracy for vid:  test16.mp4  is :  0.7023460410557185\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  184\n",
      "accuracy for vid:  test17.mp4  is :  0.7181996086105675\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  250\n",
      "accuracy for vid:  test18.mp4  is :  0.7224606580829757\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  264\n",
      "accuracy for vid:  test19.mp4  is :  0.7390710382513661\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  194\n",
      "accuracy for vid:  test20.mp4  is :  0.7808988764044944\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  168\n",
      "accuracy for vid:  test21.mp4  is :  0.825\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  182\n",
      "accuracy for vid:  test22.mp4  is :  0.7079107505070994\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  186\n",
      "accuracy for vid:  test23.mp4  is :  0.8237547892720306\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  188\n",
      "accuracy for vid:  test24.mp4  is :  0.7674418604651163\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  215\n",
      "accuracy for vid:  test25.mp4  is :  0.6932203389830508\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.165,num_fill=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  264\n",
      "accuracy for vid:  test01.mp4  is :  0.6613545816733067\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  683\n",
      "accuracy for vid:  test02.mp4  is :  0.4978448275862069\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  179\n",
      "accuracy for vid:  test03.mp4  is :  0.8667992047713717\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  174\n",
      "accuracy for vid:  test04.mp4  is :  0.7991718426501035\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  165\n",
      "accuracy for vid:  test05.mp4  is :  0.7654584221748401\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  208\n",
      "accuracy for vid:  test06.mp4  is :  0.7451327433628319\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  380\n",
      "accuracy for vid:  test07.mp4  is :  0.5798076923076924\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  159\n",
      "accuracy for vid:  test08.mp4  is :  0.8397291196388262\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  233\n",
      "accuracy for vid:  test09.mp4  is :  0.7503875968992249\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  209\n",
      "accuracy for vid:  test10.mp4  is :  0.7676056338028169\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  185\n",
      "accuracy for vid:  test11.mp4  is :  0.7719298245614035\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  146\n",
      "accuracy for vid:  test12.mp4  is :  0.8593350383631714\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  200\n",
      "accuracy for vid:  test13.mp4  is :  0.8237410071942446\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  146\n",
      "accuracy for vid:  test14.mp4  is :  0.8121827411167513\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  177\n",
      "accuracy for vid:  test15.mp4  is :  0.7665289256198347\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  255\n",
      "accuracy for vid:  test16.mp4  is :  0.7067448680351907\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  193\n",
      "accuracy for vid:  test17.mp4  is :  0.7632093933463796\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  288\n",
      "accuracy for vid:  test18.mp4  is :  0.7310443490701002\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  301\n",
      "accuracy for vid:  test19.mp4  is :  0.7581967213114754\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  218\n",
      "accuracy for vid:  test20.mp4  is :  0.7902621722846442\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  192\n",
      "accuracy for vid:  test21.mp4  is :  0.8604166666666667\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  191\n",
      "accuracy for vid:  test22.mp4  is :  0.7139959432048681\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  212\n",
      "accuracy for vid:  test23.mp4  is :  0.8352490421455939\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  203\n",
      "accuracy for vid:  test24.mp4  is :  0.7732558139534884\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  235\n",
      "accuracy for vid:  test25.mp4  is :  0.7101694915254237\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.165,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  311\n",
      "accuracy for vid:  test01.mp4  is :  0.7237715803452855\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  780\n",
      "accuracy for vid:  test02.mp4  is :  0.5005387931034483\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  197\n",
      "accuracy for vid:  test03.mp4  is :  0.8369781312127237\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  190\n",
      "accuracy for vid:  test04.mp4  is :  0.7929606625258799\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  184\n",
      "accuracy for vid:  test05.mp4  is :  0.7611940298507462\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  223\n",
      "accuracy for vid:  test06.mp4  is :  0.7097345132743362\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  417\n",
      "accuracy for vid:  test07.mp4  is :  0.5855769230769231\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  179\n",
      "accuracy for vid:  test08.mp4  is :  0.8171557562076749\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  257\n",
      "accuracy for vid:  test09.mp4  is :  0.7286821705426356\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  224\n",
      "accuracy for vid:  test10.mp4  is :  0.7535211267605634\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  197\n",
      "accuracy for vid:  test11.mp4  is :  0.7543859649122807\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  151\n",
      "accuracy for vid:  test12.mp4  is :  0.8465473145780051\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  211\n",
      "accuracy for vid:  test13.mp4  is :  0.8075539568345323\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  155\n",
      "accuracy for vid:  test14.mp4  is :  0.7868020304568528\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  196\n",
      "accuracy for vid:  test15.mp4  is :  0.743801652892562\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  275\n",
      "accuracy for vid:  test16.mp4  is :  0.7067448680351907\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  209\n",
      "accuracy for vid:  test17.mp4  is :  0.7221135029354208\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  273\n",
      "accuracy for vid:  test18.mp4  is :  0.7052932761087267\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  300\n",
      "accuracy for vid:  test19.mp4  is :  0.7418032786885246\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  207\n",
      "accuracy for vid:  test20.mp4  is :  0.7883895131086143\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  195\n",
      "accuracy for vid:  test21.mp4  is :  0.8479166666666667\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  201\n",
      "accuracy for vid:  test22.mp4  is :  0.7647058823529411\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  210\n",
      "accuracy for vid:  test23.mp4  is :  0.8314176245210728\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  218\n",
      "accuracy for vid:  test24.mp4  is :  0.7751937984496124\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  233\n",
      "accuracy for vid:  test25.mp4  is :  0.7016949152542373\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.13,num_fill=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Feature Extraction Model ...\n",
      "=> loading checkpoint '/data/disk/LUO/epoch_110_best.pth.tar'\n",
      "loading finish\n",
      "Loading from EMA model ...\n",
      "loading finish\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction configs\n",
    "args = parse_args()\n",
    "cfg = load_config(args)\n",
    "cfg.USED_GPU = 4 #make sure it is same as device\n",
    "\n",
    "tridet_cfg = load_tridet_config(\"/data/disk/LUO/test_only/TriDet/configs/cataract_slowfast.yaml\")\n",
    "ckpt_file = '/data/disk/LUO/epoch_110_best.pth.tar'\n",
    "#tridet_cfg = load_tridet_config(\"/data/disk/LUO/test_only/TriDet/configs/cataract_slowfast_0219.yaml\")\n",
    "#ckpt_file = '/data/disk/LUO/test_only/TriDet/ckpt/cataract_slowfast_0219_redivide/epoch_100.pth.tar'\n",
    "tridet_cfg['model']['test_cfg']['max_seg_num'] = topk\n",
    "print_freq = 10\n",
    "save_only = False\n",
    "\n",
    "# fix the random seeds (this will fix everything)\n",
    "_ = fix_random_seed(0, include_cuda=True)\n",
    "\n",
    "\n",
    "device = \"cuda:4\"\n",
    "extract_model = build_model(cfg).to(device)\n",
    "extract_checkpoint = torch.load(\"/data/disk/LUO/slowfast/feature_extract/checkpoints/checkpoint_epoch_00130.pyth\",map_location=device)\n",
    "print(\"Loading from Feature Extraction Model ...\")\n",
    "extract_model.load_state_dict(extract_checkpoint['model_state'])\n",
    "del extract_checkpoint\n",
    "model = make_meta_arch(tridet_cfg['model_name'], **tridet_cfg['model'])\n",
    "model = nn.DataParallel(model, device_ids=tridet_cfg['devices'])\n",
    "print(\"=> loading checkpoint '{}'\".format(ckpt_file))\n",
    "checkpoint = torch.load(\n",
    "    ckpt_file,\n",
    "    map_location=lambda storage, loc: storage.cuda(tridet_cfg['devices'][0])\n",
    ")\n",
    "print(\"loading finish\")\n",
    "# load ema model instead\n",
    "print(\"Loading from EMA model ...\")\n",
    "model.load_state_dict(checkpoint['state_dict_ema'])\n",
    "del checkpoint\n",
    "print(\"loading finish\")\n",
    "gt = pd.read_csv(\"/data/disk/LUO/test_only/r_tridet/TriDet/df_gt.csv\")\n",
    "dir_name = \"/data/disk/LUO/cataract_test_video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:4\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=64)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<64:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = frames[::2,:,:,:]\n",
    "            reversed_frames = np.flip(frames, axis=0)\n",
    "            reversed_frames = reversed_frames.copy()\n",
    "            filled_frames = np.expand_dims(frame, axis=0)\n",
    "            filled_frames = np.repeat(filled_frames, 32, axis=0)\n",
    "            #print(frames.shape)\n",
    "            #print(reversed_frames.shape)\n",
    "            #print(filled_frames.shape)\n",
    "            frames = pre_process_frame(frames)\n",
    "            reversed_frames = pre_process_frame(reversed_frames)\n",
    "            filled_frames = pre_process_frame(filled_frames)\n",
    "            \n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "\n",
    "            reversed_frame_list = pack_pathway_output(cfg, reversed_frames)\n",
    "            reversed_frame_list[0] = reversed_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            reversed_frame_list[1] = reversed_frame_list[1].unsqueeze(0)     \n",
    "\n",
    "            filled_frame_list = pack_pathway_output(cfg, filled_frames)\n",
    "            filled_frame_list[0] = filled_frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            filled_frame_list[1] = filled_frame_list[1].unsqueeze(0)   \n",
    "\n",
    "\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    reversed_frame_wise_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    reversed_cur_feature = test(extract_model,cfg,reversed_frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    reversed_frame_wise_feature =  np.concatenate((reversed_cur_feature,reversed_frame_wise_feature),axis=0)\n",
    "\n",
    "                    filled_frame_wise_feature = test(extract_model,cfg,filled_frame_list)\n",
    "                    #print(reversed_frame_wise_feature.shape)\n",
    "                    #print(filled_frame_wise_feature.shape)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #inference\n",
    "                mirror_features = mirror_feature(inputs,reversed_frame_wise_feature,filled_frame_wise_feature,num_fill)\n",
    "                results = valid_one_epoch([mirror_features],model=model)\n",
    "                df = to_df(results)\n",
    "                if inputs[\"feats\"].size(1) >= 1024:\n",
    "                    pred_label,score = get_middle_label(df,[512-num_fill//2,512+num_fill//2],threshold)\n",
    "                else:\n",
    "                    pred_label,score = get_middle_label(df,[cur_second,cur_second+num_fill],threshold=threshold)\n",
    "\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-20-13-34-12_result\n",
      "Eval video:  test01.mp4  ...\n",
      "total time:  477\n",
      "accuracy for vid:  test01.mp4  is :  0.6875\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1183\n",
      "accuracy for vid:  test02.mp4  is :  0.415633423180593\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  326\n",
      "accuracy for vid:  test03.mp4  is :  0.8143712574850299\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  312\n",
      "accuracy for vid:  test04.mp4  is :  0.8049792531120332\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  303\n",
      "accuracy for vid:  test05.mp4  is :  0.7558886509635975\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  371\n",
      "accuracy for vid:  test06.mp4  is :  0.8156028368794326\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  676\n",
      "accuracy for vid:  test07.mp4  is :  0.615606936416185\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  288\n",
      "accuracy for vid:  test08.mp4  is :  0.8461538461538461\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  425\n",
      "accuracy for vid:  test09.mp4  is :  0.7701863354037267\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  368\n",
      "accuracy for vid:  test10.mp4  is :  0.7971781305114638\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  337\n",
      "accuracy for vid:  test11.mp4  is :  0.744140625\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  249\n",
      "accuracy for vid:  test12.mp4  is :  0.7717948717948718\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  360\n",
      "accuracy for vid:  test13.mp4  is :  0.8050541516245487\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  258\n",
      "accuracy for vid:  test14.mp4  is :  0.7964376590330788\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  318\n",
      "accuracy for vid:  test15.mp4  is :  0.7577639751552795\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  438\n",
      "accuracy for vid:  test16.mp4  is :  0.6417033773861968\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  332\n",
      "accuracy for vid:  test17.mp4  is :  0.7352941176470589\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  449\n",
      "accuracy for vid:  test18.mp4  is :  0.7245337159253945\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  467\n",
      "accuracy for vid:  test19.mp4  is :  0.7455540355677155\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  348\n",
      "accuracy for vid:  test20.mp4  is :  0.8048780487804879\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  306\n",
      "accuracy for vid:  test21.mp4  is :  0.81419624217119\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  310\n",
      "accuracy for vid:  test22.mp4  is :  0.7012195121951219\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  327\n",
      "accuracy for vid:  test23.mp4  is :  0.8157389635316699\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  320\n",
      "accuracy for vid:  test24.mp4  is :  0.8233009708737864\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  387\n",
      "accuracy for vid:  test25.mp4  is :  0.7521222410865874\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.13,num_fill=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-20-16-19-59_result\n",
      "Eval video:  test01.mp4  ...\n",
      "total time:  482\n",
      "accuracy for vid:  test01.mp4  is :  0.6848404255319149\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1196\n",
      "accuracy for vid:  test02.mp4  is :  0.40431266846361186\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  328\n",
      "accuracy for vid:  test03.mp4  is :  0.7944111776447106\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  310\n",
      "accuracy for vid:  test04.mp4  is :  0.8091286307053942\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  301\n",
      "accuracy for vid:  test05.mp4  is :  0.7323340471092077\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  362\n",
      "accuracy for vid:  test06.mp4  is :  0.8138297872340425\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  678\n",
      "accuracy for vid:  test07.mp4  is :  0.6040462427745664\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  283\n",
      "accuracy for vid:  test08.mp4  is :  0.8461538461538461\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  418\n",
      "accuracy for vid:  test09.mp4  is :  0.7639751552795031\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  369\n",
      "accuracy for vid:  test10.mp4  is :  0.781305114638448\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  333\n",
      "accuracy for vid:  test11.mp4  is :  0.73046875\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  258\n",
      "accuracy for vid:  test12.mp4  is :  0.7666666666666667\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  359\n",
      "accuracy for vid:  test13.mp4  is :  0.7888086642599278\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  250\n",
      "accuracy for vid:  test14.mp4  is :  0.7811704834605598\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  317\n",
      "accuracy for vid:  test15.mp4  is :  0.7370600414078675\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  447\n",
      "accuracy for vid:  test16.mp4  is :  0.6284875183553598\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  328\n",
      "accuracy for vid:  test17.mp4  is :  0.7058823529411765\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  456\n",
      "accuracy for vid:  test18.mp4  is :  0.7288378766140603\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  473\n",
      "accuracy for vid:  test19.mp4  is :  0.7414500683994528\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  349\n",
      "accuracy for vid:  test20.mp4  is :  0.7729831144465291\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  310\n",
      "accuracy for vid:  test21.mp4  is :  0.81419624217119\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  323\n",
      "accuracy for vid:  test22.mp4  is :  0.6869918699186992\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  342\n",
      "accuracy for vid:  test23.mp4  is :  0.8061420345489443\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  322\n",
      "accuracy for vid:  test24.mp4  is :  0.8097087378640777\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  370\n",
      "accuracy for vid:  test25.mp4  is :  0.735144312393888\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.1,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-20-19-06-14_result\n",
      "Eval video:  test01.mp4  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time:  495\n",
      "accuracy for vid:  test01.mp4  is :  0.6781914893617021\n",
      "Eval video:  test02.mp4  ...\n",
      "total time:  1206\n",
      "accuracy for vid:  test02.mp4  is :  0.42048517520215634\n",
      "Eval video:  test03.mp4  ...\n",
      "total time:  330\n",
      "accuracy for vid:  test03.mp4  is :  0.8163672654690619\n",
      "Eval video:  test04.mp4  ...\n",
      "total time:  313\n",
      "accuracy for vid:  test04.mp4  is :  0.8070539419087137\n",
      "Eval video:  test05.mp4  ...\n",
      "total time:  301\n",
      "accuracy for vid:  test05.mp4  is :  0.7494646680942184\n",
      "Eval video:  test06.mp4  ...\n",
      "total time:  370\n",
      "accuracy for vid:  test06.mp4  is :  0.8191489361702128\n",
      "Eval video:  test07.mp4  ...\n",
      "total time:  664\n",
      "accuracy for vid:  test07.mp4  is :  0.6165703275529865\n",
      "Eval video:  test08.mp4  ...\n",
      "total time:  287\n",
      "accuracy for vid:  test08.mp4  is :  0.8484162895927602\n",
      "Eval video:  test09.mp4  ...\n",
      "total time:  418\n",
      "accuracy for vid:  test09.mp4  is :  0.765527950310559\n",
      "Eval video:  test10.mp4  ...\n",
      "total time:  370\n",
      "accuracy for vid:  test10.mp4  is :  0.7918871252204586\n",
      "Eval video:  test11.mp4  ...\n",
      "total time:  331\n",
      "accuracy for vid:  test11.mp4  is :  0.73828125\n",
      "Eval video:  test12.mp4  ...\n",
      "total time:  244\n",
      "accuracy for vid:  test12.mp4  is :  0.7871794871794872\n",
      "Eval video:  test13.mp4  ...\n",
      "total time:  350\n",
      "accuracy for vid:  test13.mp4  is :  0.7906137184115524\n",
      "Eval video:  test14.mp4  ...\n",
      "total time:  245\n",
      "accuracy for vid:  test14.mp4  is :  0.7913486005089059\n",
      "Eval video:  test15.mp4  ...\n",
      "total time:  302\n",
      "accuracy for vid:  test15.mp4  is :  0.7494824016563147\n",
      "Eval video:  test16.mp4  ...\n",
      "total time:  429\n",
      "accuracy for vid:  test16.mp4  is :  0.6490455212922174\n",
      "Eval video:  test17.mp4  ...\n",
      "total time:  327\n",
      "accuracy for vid:  test17.mp4  is :  0.7313725490196078\n",
      "Eval video:  test18.mp4  ...\n",
      "total time:  424\n",
      "accuracy for vid:  test18.mp4  is :  0.727403156384505\n",
      "Eval video:  test19.mp4  ...\n",
      "total time:  452\n",
      "accuracy for vid:  test19.mp4  is :  0.7455540355677155\n",
      "Eval video:  test20.mp4  ...\n",
      "total time:  325\n",
      "accuracy for vid:  test20.mp4  is :  0.8142589118198874\n",
      "Eval video:  test21.mp4  ...\n",
      "total time:  308\n",
      "accuracy for vid:  test21.mp4  is :  0.8079331941544885\n",
      "Eval video:  test22.mp4  ...\n",
      "total time:  324\n",
      "accuracy for vid:  test22.mp4  is :  0.6951219512195121\n",
      "Eval video:  test23.mp4  ...\n",
      "total time:  323\n",
      "accuracy for vid:  test23.mp4  is :  0.817658349328215\n",
      "Eval video:  test24.mp4  ...\n",
      "total time:  339\n",
      "accuracy for vid:  test24.mp4  is :  0.8194174757281554\n",
      "Eval video:  test25.mp4  ...\n",
      "total time:  386\n",
      "accuracy for vid:  test25.mp4  is :  0.7470288624787776\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(vid,log_folder,threshold=0.1,num_fill=32):    \n",
    "    print(\"Eval video: \",vid,\" ...\")\n",
    "    vid_path = os.path.join(dir_name,vid)\n",
    "    device = \"cuda:4\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    sample_height = 256\n",
    "    sample_width = 256\n",
    "    count = 0\n",
    "    seq_length = 32\n",
    "    queue = deque(maxlen=32)\n",
    "    ret = True\n",
    "    frame_wise_feature = None\n",
    "    idx = int(vid_path.split(\"/\")[-1].split(\".\")[0].split(\"test\")[-1])-1 #test01 -> 0\n",
    "    dict_db,label_dict = _load_json() #dict_db contains segments and labels\n",
    "    current_db = dict_db[idx] #current test file json\n",
    "    count_2 = 0 #count after queue is full\n",
    "    # load tridet model\n",
    "    # not ideal for multi GPU training, ok for now\n",
    "\n",
    "    # load ckpt, reset epoch / best rmse\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "    start = datetime.datetime.now()\n",
    "    while ret:\n",
    "        #print(\"count: \",count)\n",
    "        \n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"finished\")\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        frame = cv2.resize(frame,(sample_height,sample_width),interpolation = cv2.INTER_LINEAR)\n",
    "        queue.append(frame)\n",
    "        if count<32:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            frames = np.stack(queue, axis=0)\n",
    "            frames = pre_process_frame(frames)\n",
    "            frame_list = pack_pathway_output(cfg, frames) #得到一个list,list[0]为(3,8,256,256),[1]为[3,32,256,256]分别表示slow和fast两条线\n",
    "            frame_list[0] = frame_list[0].unsqueeze(0) #增加一个batch维度\n",
    "            frame_list[1] = frame_list[1].unsqueeze(0)\n",
    "            if count_2%30 == 0: #每30表示的是每30个frame，即每一秒取一次feature\n",
    "                cur_second = count//30\n",
    "                #print(\"current second: \",cur_second)\n",
    "                if frame_wise_feature is None:\n",
    "                    frame_wise_feature = test(extract_model,cfg,frame_list) #得到每32个frame为单位的一个feature，size大小为(1,2304)\n",
    "                    #print(\"frame_wise_feture\",frame_wise_feture.shape)\n",
    "                    #print(test(cfg,frame_list))\n",
    "                else:\n",
    "                    #print(\"frame_wise_feture \",frame_wise_feture.shape)\n",
    "                    cur_feature = test(extract_model,cfg,frame_list)\n",
    "                    #print(\"cur_feature \",cur_feature.shape)\n",
    "                    frame_wise_feature = np.concatenate((frame_wise_feature,cur_feature),axis=0)\n",
    "                    #print(frame_wise_feture.shape)\n",
    "                    #将frame_wise_feature 在dim 0 上concate起来，放入surgplan的eval方程\n",
    "                \n",
    "                \n",
    "                #transfer input frame_wise_features into dictionary\n",
    "                inputs = getitem(data_list=dict_db,features=frame_wise_feature, idx=idx,num_frames=len(frame_wise_feature))\n",
    "                #ret = False\n",
    "                #inference\n",
    "                results = valid_one_epoch([mirror_feature(inputs,num_fill)],model=model)\n",
    "                df = to_df(results)\n",
    "                if inputs[\"feats\"].size(1) >= 1024:\n",
    "                    pred_label,score = get_middle_label(df,[512-num_fill//2,512+num_fill//2],threshold)\n",
    "                else:\n",
    "                    pred_label,score = get_middle_label(df,[cur_second,cur_second+num_fill],threshold)\n",
    "                #print(\"predicted label: \",pred_label,\" score:\",score)\n",
    "                pred_list.append(pred_label)\n",
    "                score_list.append(score)\n",
    "            count+=1\n",
    "            count_2 +=1 \n",
    "    end = datetime.datetime.now()\n",
    "    cap.release()\n",
    "    print(\"total time: \", (end-start).seconds)\n",
    "    acc = accuracy_score(gt[gt[\"video_id\"]==vid][\"gt_labels\"][-len(pred_list):],pred_list[:])\n",
    "    print(\"accuracy for vid: \",vid,\" is : \",acc)\n",
    "    \n",
    "    x = gt[gt[\"video_id\"]==vid][-len(pred_list):]\n",
    "    x[\"pred_labels\"] = pred_list\n",
    "    x[\"pred_scores\"] = score_list\n",
    "\n",
    "    csv_file = \"./\"+log_folder+\"/result_real_time_\"+vid+\".csv\"\n",
    "    x.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-20-21-50-50_result\n",
      "Eval video:  test01.mp4  ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mirror_feature() missing 2 required positional arguments: 'filled_inputs' and 'num_fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(cur_time)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/disk/LUO/cataract_test_video\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcur_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 66\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(vid, log_folder, threshold, num_fill)\u001b[0m\n\u001b[1;32m     63\u001b[0m inputs \u001b[38;5;241m=\u001b[39m getitem(data_list\u001b[38;5;241m=\u001b[39mdict_db,features\u001b[38;5;241m=\u001b[39mframe_wise_feature, idx\u001b[38;5;241m=\u001b[39midx,num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(frame_wise_feature))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#ret = False\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#inference\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m results \u001b[38;5;241m=\u001b[39m valid_one_epoch([\u001b[43mmirror_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_fill\u001b[49m\u001b[43m)\u001b[49m],model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     67\u001b[0m df \u001b[38;5;241m=\u001b[39m to_df(results)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeats\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: mirror_feature() missing 2 required positional arguments: 'filled_inputs' and 'num_fill'"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.13,num_fill=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02-04-49-33_result\n",
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  951\n",
      "accuracy for vid:  test01.mp4  is :  0.6772908366533864\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  2369\n",
      "accuracy for vid:  test02.mp4  is :  0.47629310344827586\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  658\n",
      "accuracy for vid:  test03.mp4  is :  0.709741550695825\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  560\n",
      "accuracy for vid:  test04.mp4  is :  0.6128364389233955\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  573\n",
      "accuracy for vid:  test05.mp4  is :  0.5970149253731343\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  699\n",
      "accuracy for vid:  test06.mp4  is :  0.6070796460176991\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  1341\n",
      "accuracy for vid:  test07.mp4  is :  0.5221153846153846\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  517\n",
      "accuracy for vid:  test08.mp4  is :  0.6388261851015802\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  767\n",
      "accuracy for vid:  test09.mp4  is :  0.6713178294573643\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  723\n",
      "accuracy for vid:  test10.mp4  is :  0.6619718309859155\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  649\n",
      "accuracy for vid:  test11.mp4  is :  0.621832358674464\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  480\n",
      "accuracy for vid:  test12.mp4  is :  0.59846547314578\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  661\n",
      "accuracy for vid:  test13.mp4  is :  0.6420863309352518\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  467\n",
      "accuracy for vid:  test14.mp4  is :  0.6218274111675127\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  484\n",
      "accuracy for vid:  test15.mp4  is :  0.6549586776859504\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  360\n",
      "accuracy for vid:  test16.mp4  is :  0.5997067448680352\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  276\n",
      "accuracy for vid:  test17.mp4  is :  0.5831702544031311\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  383\n",
      "accuracy for vid:  test18.mp4  is :  0.6137339055793991\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  390\n",
      "accuracy for vid:  test19.mp4  is :  0.6311475409836066\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  305\n",
      "accuracy for vid:  test20.mp4  is :  0.6872659176029963\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  254\n",
      "accuracy for vid:  test21.mp4  is :  0.66875\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  307\n",
      "accuracy for vid:  test22.mp4  is :  0.6004056795131846\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  294\n",
      "accuracy for vid:  test23.mp4  is :  0.6934865900383141\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  267\n",
      "accuracy for vid:  test24.mp4  is :  0.7151162790697675\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  302\n",
      "accuracy for vid:  test25.mp4  is :  0.5983050847457627\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.1,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02-09-00-26_result\n",
      "Eval video:  test01.mp4  ...\n",
      "finished\n",
      "total time:  420\n",
      "accuracy for vid:  test01.mp4  is :  0.6772908366533864\n",
      "Eval video:  test02.mp4  ...\n",
      "finished\n",
      "total time:  1059\n",
      "accuracy for vid:  test02.mp4  is :  0.5053879310344828\n",
      "Eval video:  test03.mp4  ...\n",
      "finished\n",
      "total time:  293\n",
      "accuracy for vid:  test03.mp4  is :  0.7196819085487077\n",
      "Eval video:  test04.mp4  ...\n",
      "finished\n",
      "total time:  290\n",
      "accuracy for vid:  test04.mp4  is :  0.6252587991718427\n",
      "Eval video:  test05.mp4  ...\n",
      "finished\n",
      "total time:  279\n",
      "accuracy for vid:  test05.mp4  is :  0.6183368869936035\n",
      "Eval video:  test06.mp4  ...\n",
      "finished\n",
      "total time:  330\n",
      "accuracy for vid:  test06.mp4  is :  0.6212389380530974\n",
      "Eval video:  test07.mp4  ...\n",
      "finished\n",
      "total time:  617\n",
      "accuracy for vid:  test07.mp4  is :  0.5125\n",
      "Eval video:  test08.mp4  ...\n",
      "finished\n",
      "total time:  246\n",
      "accuracy for vid:  test08.mp4  is :  0.654627539503386\n",
      "Eval video:  test09.mp4  ...\n",
      "finished\n",
      "total time:  351\n",
      "accuracy for vid:  test09.mp4  is :  0.6883720930232559\n",
      "Eval video:  test10.mp4  ...\n",
      "finished\n",
      "total time:  301\n",
      "accuracy for vid:  test10.mp4  is :  0.6654929577464789\n",
      "Eval video:  test11.mp4  ...\n",
      "finished\n",
      "total time:  536\n",
      "accuracy for vid:  test11.mp4  is :  0.6179337231968811\n",
      "Eval video:  test12.mp4  ...\n",
      "finished\n",
      "total time:  469\n",
      "accuracy for vid:  test12.mp4  is :  0.6010230179028133\n",
      "Eval video:  test13.mp4  ...\n",
      "finished\n",
      "total time:  634\n",
      "accuracy for vid:  test13.mp4  is :  0.7122302158273381\n",
      "Eval video:  test14.mp4  ...\n",
      "finished\n",
      "total time:  419\n",
      "accuracy for vid:  test14.mp4  is :  0.6370558375634517\n",
      "Eval video:  test15.mp4  ...\n",
      "finished\n",
      "total time:  539\n",
      "accuracy for vid:  test15.mp4  is :  0.6611570247933884\n",
      "Eval video:  test16.mp4  ...\n",
      "finished\n",
      "total time:  837\n",
      "accuracy for vid:  test16.mp4  is :  0.5997067448680352\n",
      "Eval video:  test17.mp4  ...\n",
      "finished\n",
      "total time:  590\n",
      "accuracy for vid:  test17.mp4  is :  0.6046966731898239\n",
      "Eval video:  test18.mp4  ...\n",
      "finished\n",
      "total time:  825\n",
      "accuracy for vid:  test18.mp4  is :  0.6337625178826896\n",
      "Eval video:  test19.mp4  ...\n",
      "finished\n",
      "total time:  876\n",
      "accuracy for vid:  test19.mp4  is :  0.639344262295082\n",
      "Eval video:  test20.mp4  ...\n",
      "finished\n",
      "total time:  623\n",
      "accuracy for vid:  test20.mp4  is :  0.6872659176029963\n",
      "Eval video:  test21.mp4  ...\n",
      "finished\n",
      "total time:  590\n",
      "accuracy for vid:  test21.mp4  is :  0.6708333333333333\n",
      "Eval video:  test22.mp4  ...\n",
      "finished\n",
      "total time:  587\n",
      "accuracy for vid:  test22.mp4  is :  0.5882352941176471\n",
      "Eval video:  test23.mp4  ...\n",
      "finished\n",
      "total time:  569\n",
      "accuracy for vid:  test23.mp4  is :  0.6934865900383141\n",
      "Eval video:  test24.mp4  ...\n",
      "finished\n",
      "total time:  597\n",
      "accuracy for vid:  test24.mp4  is :  0.7151162790697675\n",
      "Eval video:  test25.mp4  ...\n",
      "finished\n",
      "total time:  683\n",
      "accuracy for vid:  test25.mp4  is :  0.5983050847457627\n"
     ]
    }
   ],
   "source": [
    "cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_result\"\n",
    "print(cur_time)\n",
    "os.mkdir(cur_time)\n",
    "for i in os.listdir(\"/data/disk/LUO/cataract_test_video\"):\n",
    "    main(i,cur_time,threshold=0.15,num_fill=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrcn = pd.read_csv(\"/data/disk/video_detection/SVRC/experiment/20231109-233357__SGD_lr0.01_factor1.0_step5_gamma0.5_wd1e-06_noseed/result-best-8-acc72.11-f58.73-recall60.65-prec62.33-jmicro56.39/tmp_preds_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/disk/LUO/test_only/r_tridet/TriDet/data/cataract/data_1102.json\",\"r\") as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/disk/LUO/test_only/r_tridet/TriDet/data/cataract/data_1102_indent.json\",\"w\") as f:\n",
    "    f.write(json.dumps(json_data,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tools',\n",
       " 'out_cls_logits.pkl',\n",
       " 'requirements.txt',\n",
       " 'train.py',\n",
       " 'prediction_cataracts.csv',\n",
       " 'transform_to_acc.ipynb',\n",
       " 'framework.jpg',\n",
       " 'temp_test.ipynb',\n",
       " 'generate_json.ipynb',\n",
       " 'eval.py',\n",
       " 'df_pred.csv',\n",
       " 'generate_dataset.py',\n",
       " 'data_1106.json',\n",
       " 'ground_truth_cataracts.csv',\n",
       " 'data_cataracts.json',\n",
       " 'SCRV-Net_epoch0.csv',\n",
       " 'ground_truth.csv',\n",
       " 'calculate_map.ipynb',\n",
       " 'SVRC-Net.csv',\n",
       " 'configs',\n",
       " 'prediction.csv',\n",
       " 'README.md',\n",
       " 'temp.csv',\n",
       " 'TeCNO_tmp_preds_gt.csv',\n",
       " 'df_gt.csv',\n",
       " 'data_1220.json',\n",
       " 'lxj.code-workspace',\n",
       " '.git',\n",
       " 'libs',\n",
       " 'ckpt_none_finetune',\n",
       " 'ckpt',\n",
       " 'data',\n",
       " 'real_time_tridet.ipynb',\n",
       " 'feature_extract',\n",
       " 'real_time_ckpt',\n",
       " 'gt_video3.csv',\n",
       " 'real_time_surgplan.csv',\n",
       " 'result_real_time.csv',\n",
       " 'real_time_json_generate.ipynb',\n",
       " 'result_real_time_test01.mp4.csv',\n",
       " 'eval_csv',\n",
       " '2024-02-20-13-34-12_result',\n",
       " 'gt_pred_df.csv',\n",
       " '2024-01-31-00-32-00_result',\n",
       " '2024-02-20-16-19-59_result',\n",
       " '2024-01-31-14-01-55_result',\n",
       " '2024-01-31-17-39-40_result',\n",
       " '2024-02-01-00-11-22_result',\n",
       " '2024-02-01-01-58-39_result',\n",
       " '2024-02-01-03-44-11_result',\n",
       " '2024-02-01-05-30-02_result',\n",
       " '2024-02-01-07-09-42_result',\n",
       " '2024-02-01-08-42-49_result',\n",
       " '2024-02-01-10-19-39_result',\n",
       " '2024-02-01-12-03-06_result',\n",
       " '2024-02-01-13-50-27_result',\n",
       " '2024-02-20-19-06-14_result',\n",
       " 'real_time_tridet_2.ipynb',\n",
       " '2024-02-20-21-50-50_result',\n",
       " '2024-02-01-14-54-35_result',\n",
       " '2024-02-01-17-30-33_result',\n",
       " '2024-02-01-18-10-40_result',\n",
       " '2024-02-01-21-44-35_result',\n",
       " '2024-02-01-23-13-44_result',\n",
       " '2024-02-02-01-20-37_result',\n",
       " '2024-02-02-04-49-13_result',\n",
       " '2024-02-02-04-49-33_result',\n",
       " '2024-02-02-09-00-26_result',\n",
       " '2024-02-02-10-12-01_result',\n",
       " '2024-02-02-10-52-20_result',\n",
       " '2024-02-05-16-06-32_result',\n",
       " '2024-02-05-16-07-12_result',\n",
       " '2024-02-05-16-55-49_result',\n",
       " '2024-02-05-17-14-45_result',\n",
       " '2024-02-05-17-37-01_result',\n",
       " '2024-02-06-11-49-05_result',\n",
       " 'real_time_tridet_3.ipynb',\n",
       " '2024-02-19-17-48-48_result',\n",
       " '2024-02-19-17-50-29_result',\n",
       " '2024-02-19-17-51-26_result',\n",
       " '2024-02-19-18-05-31_result',\n",
       " '2024-02-20-09-12-01_result',\n",
       " '2024-02-20-11-32-41_result']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/data/disk/LUO/test_only/r_tridet/TriDet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-02-27-08-44-57_result mirror\n",
    "# /home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/2024-02-27-06-57-01_result fill\n",
    "# /home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/2024-02-27-01-45-55_result pure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best result : /home/lxj/project/surgplan/LUO/test_only/r_tridet/TriDet/2024-02-01-14-54-35_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths =['2024-02-27-08-44-57_result','2024-02-27-06-57-01_result','2024-02-27-01-45-55_result','2024-02-01-14-54-35_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths =['2024-02-27-06-57-01_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_list = [\"result_real_time_test02.mp4.csv\",\"result_real_time_test01.mp4.csv\",\"result_real_time_test05.mp4.csv\",\"result_real_time_test06.mp4.csv\",\"result_real_time_test22.mp4.csv\",\"result_real_time_test16.mp4.csv\",\"result_real_time_test07.mp4.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27-08-44-57_result\n",
      "accuracy:  0.41077229382793673\n",
      "f1:  0.37853040271873933\n",
      "recall:  0.41077229382793673\n",
      "precision:  0.4365790010099536\n",
      "jaccard_score:  0.2688722118493837\n",
      "2024-02-27-06-57-01_result\n",
      "accuracy:  0.7085822068531908\n",
      "f1:  0.7227190458239079\n",
      "recall:  0.7085822068531908\n",
      "precision:  0.8053961428204539\n",
      "jaccard_score:  0.5821855005094329\n",
      "2024-02-27-01-45-55_result\n",
      "accuracy:  0.48433406685528657\n",
      "f1:  0.460863055879541\n",
      "recall:  0.48433406685528657\n",
      "precision:  0.7639914038015739\n",
      "jaccard_score:  0.3250881029453467\n",
      "2024-02-01-14-54-35_result\n",
      "accuracy:  0.7969468841488917\n",
      "f1:  0.7926846714414777\n",
      "recall:  0.7969468841488917\n",
      "precision:  0.8158471268342117\n",
      "jaccard_score:  0.6678067484365463\n"
     ]
    }
   ],
   "source": [
    "for dir_path in dir_paths:\n",
    "    print(dir_path)\n",
    "    csv_files = os.listdir(dir_path)\n",
    "    \n",
    "    df = None\n",
    "    for file in csv_files:\n",
    "        if file in ban_list:\n",
    "            continue\n",
    "        file_path = os.path.join(dir_path,file)\n",
    "        if df is None:\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            df = pd.concat([df,pd.read_csv(file_path)])\n",
    "    print(\"accuracy: \",accuracy_score(df[\"gt_labels\"],df[\"pred_labels\"]))\n",
    "    print(\"f1: \",f1_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))\n",
    "    print(\"recall: \",recall_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))\n",
    "\n",
    "    print(\"precision: \",precision_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))\n",
    "    print(\"jaccard_score: \",jaccard_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:  0.36091245026382723\n"
     ]
    }
   ],
   "source": [
    "print(\"f1: \",f1_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.7587416672092856\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \",precision_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  0.7342757100246401\n"
     ]
    }
   ],
   "source": [
    "print(\"recall: \",recall_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_score:  0.6678067484365463\n"
     ]
    }
   ],
   "source": [
    "print(\"jaccard_score: \",jaccard_score(df[\"gt_labels\"],df[\"pred_labels\"],average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_score(y_true[0], y_pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f36cc76d360>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "cm = confusion_matrix(df[\"gt_labels\"], df[\"pred_labels\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm\n",
    "                          )\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tridet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
